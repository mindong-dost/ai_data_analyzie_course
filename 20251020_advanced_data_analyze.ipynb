{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimjy-par/ai_data_analyzie_course/blob/main/20251020_advanced_data_analyze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf0ab92"
      },
      "source": [
        "# YouTube 채널 분석 실습 개요\n",
        "\n",
        "* * *\n",
        "\n",
        "본 실습은 YouTube Data API와 Google Gemini API를 활용하여 특정 YouTube 채널의 영상 및 댓글 데이터를 수집하고 분석하는 과정을 다룹니다. ** 수강생 분들은 미리 작성된 함수를 활용하여 간단하게 자동으로 실행하고 그 결과를 확인하는 데 중점을 둡니다.** 수집된 데이터를 바탕으로 AI 모델을 통해 심층적인 분석 리포트를 생성하고, 이를 통해 콘텐츠 기획 및 채널 운영 전략에 대한 실질적인 인사이트를 얻는 것을 목표로 합니다.\n",
        "\n",
        "# 실습 목표:\n",
        "\n",
        "* * *\n",
        "\n",
        "1.  **미리 작성된 함수를 활용하여 각 단계 별로 처리된 결과를 자동으로 확인하고 전체 분석 파이프라인을 실행할 수 있다.**\n",
        "2.  **수집 설정 (영상 개수, 댓글 개수 등) 및 AI 프롬프트를 수정하여 분석을 다시 시작할 수 있다.**\n",
        "3. **(가능하다면) 코드를 응용하여 원하는 분석 결과를 도출할 수 있다.**\n",
        "\n",
        "\n",
        "# 실습 전 준비사항:\n",
        "\n",
        "* * *\n",
        "\n",
        "1. YouTube Data API 키 (무료, [구글클라우드 링크](https://console.cloud.google.com/projectselector2/apis/dashboard?supportedpurview=project&project=&folder=&organizationId=))\n",
        "2. Google Gemini API 키 (무료, https://aistudio.google.com/)\n",
        "3. 분석하고 싶은 YouTube 채널명 (예: @도프프스튜디오)\n",
        "\n",
        "# 실습 절차\n",
        "* * *\n",
        "\n",
        "1.  **필요 라이브러리 설치 및 환경 설정**: YouTube API 및 Gemini API 사용을 위한 라이브러리를 설치하고 API 키를 설정합니다. Google Drive 연결을 통해 분석 결과를 저장할 환경을 준비합니다.\n",
        "2.  **YouTube 데이터 수집**: 특정 채널의 동영상 목록을 가져오고, 각 영상에 대한 댓글을 수집합니다. 수집 범위 (영상 개수, 댓글 개수 등)를 설정하여 원하는 데이터를 확보합니다.\n",
        "3.  **데이터 전처리 및 저장**: 수집된 영상 및 댓글 데이터를 분석 가능한 형태로 가공하고, 추후 활용을 위해 파일로 저장합니다.\n",
        "4.  **AI 분석 리포트 생성**: 전처리된 데이터를 바탕으로 Gemini AI 모델에 분석을 요청하고, AI가 생성한 분석 리포트를 확인합니다.\n",
        "\n",
        "* * *\n",
        "\n",
        "**참고사항:**\n",
        "\n",
        "*   실습 중 API 할당량에 유의하여 진행합니다.\n",
        "    -   유튜브 데이터 수집과 GEMINI 모두 할당량이 존재합니다. 현재는 무료플랜을 사용하므로 API 사용량을 유의하여 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylkFs9pIRZaE"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리를 모두 설치합니다 (한번만 실행)\n",
        "!pip install yt-dlp google-api-python-client google-genai wordcloud\n",
        "\n",
        "# 필요한 모든 라이브러리를 한번에 불러옵니다\n",
        "import os                      # 파일과 폴더 관리용\n",
        "import json                    # JSON 데이터 처리용\n",
        "import time                    # 시간 지연용\n",
        "import pandas as pd            # 데이터 분석용 (엑셀과 비슷)\n",
        "import matplotlib.pyplot as plt # 그래프 그리기용\n",
        "import numpy as np             # 수학 계산용\n",
        "from collections import Counter # 빈도 계산용\n",
        "import re                      # 텍스트 처리용\n",
        "from datetime import datetime, timedelta  # 날짜 계산용\n",
        "import subprocess              # 외부 프로그램 실행용\n",
        "\n",
        "\n",
        "# Google Drive를 연결합니다 (결과 저장용)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# YouTube 데이터를 가져오는 라이브러리\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "\n",
        "# AI 분석용 라이브러리\n",
        "from google import genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경 설정\n",
        "YOUTUBE_API_KEY = \"유튜브 API KEY\"  # YouTube Data API 키\n",
        "GEMINI_API_KEY = \"GEMINI API KEY\"    # Gemini AI 키"
      ],
      "metadata": {
        "id": "1uVHRXzpqmgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 이 셀은 절대 수정하지 마세요.\n",
        "# 함수와 코드 설정이 포함되어 있습니다.\n",
        "# =================================================================\n",
        "\n",
        "MAX_VIDEOS = 10             # 분석할 영상 개수 (10개)\n",
        "MAX_RAW_VIDEOS = 500       # 인기순 혹은 최신순 정렬을 위해 가져올 비디오 개수\n",
        "MAX_COMMENTS_PER_VIDEO = 20 # 영상당 댓글 개수 (20개)\n",
        "\n",
        "# 결과 저장할 폴더 설정\n",
        "SAVE_PATH = \"/content/drive/MyDrive/youtube_analysis/\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)  # 폴더가 없으면 자동 생성\n",
        "\n",
        "print(\"설정 완료!\")\n",
        "print(f\"저장 위치: {SAVE_PATH}\")\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# API 연결 설정\n",
        "# =================================================================\n",
        "\n",
        "# YouTube Data API 연결\n",
        "try:\n",
        "    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
        "    print(\"YouTube API 연결 성공!\")\n",
        "except Exception as e:\n",
        "    print(f\"YouTube API 연결 실패: {e}\")\n",
        "    print(\"API 키를 확인해주세요\")\n",
        "\n",
        "# Gemini AI 연결\n",
        "try:\n",
        "    os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "    genai_client = genai.Client()\n",
        "    print(\"Gemini AI 연결 성공!\")\n",
        "except Exception as e:\n",
        "    print(f\"Gemini AI 연결 실패: {e}\")\n",
        "    print(\"API 키를 확인해주세요\")\n",
        "\n",
        "\n",
        "\n",
        "def get_channel_id_by_handle(handle):\n",
        "    \"\"\"채널 핸들로 실제 채널 ID를 찾는 함수\"\"\"\n",
        "    try:\n",
        "        handle = handle.replace('@', '')\n",
        "        request = youtube.search().list(\n",
        "            part='snippet',\n",
        "            q=handle,\n",
        "            type='channel',\n",
        "            maxResults=1\n",
        "        )\n",
        "        response = request.execute()\n",
        "        if response['items']:\n",
        "            return response['items'][0]['snippet']['channelId']\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"채널 ID 찾기 에러: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_all_channel_videos(youtube, channel_id, limit=MAX_RAW_VIDEOS):\n",
        "    \"\"\"\n",
        "    지정된 채널의 동영상 상세 정보를 지정된 최대 개수(limit)만큼만 가져옵니다.\n",
        "\n",
        "    Args:\n",
        "        youtube: YouTube API 서비스 객체\n",
        "        channel_id (str): 조회할 채널의 ID\n",
        "        limit (int): 가져올 최대 동영상 개수\n",
        "\n",
        "    Returns:\n",
        "        list: 채널의 동영상 정보가 담긴 리스트\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # (이전과 동일) 채널의 '업로드' 재생목록 ID 가져오기\n",
        "        channel_response = youtube.channels().list(part='contentDetails', id=channel_id).execute()\n",
        "        uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "\n",
        "        video_ids = []\n",
        "        next_page_token = None\n",
        "\n",
        "        # while 루프 시작\n",
        "        while True:\n",
        "            playlist_response = youtube.playlistItems().list(\n",
        "                part='contentDetails',\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            video_ids.extend([item['contentDetails']['videoId'] for item in playlist_response['items']])\n",
        "\n",
        "            # --- ✨ 핵심 수정 부분 ---\n",
        "            # 1. 현재까지 가져온 동영상 개수가 limit을 넘었는지 확인\n",
        "            if len(video_ids) >= limit:\n",
        "                break # 넘었다면 루프 중단\n",
        "\n",
        "            next_page_token = playlist_response.get('nextPageToken')\n",
        "\n",
        "            # 2. 다음 페이지가 없어도 루프 중단\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        # --- ✨ 가져온 ID 개수에 맞춰 자르기 ---\n",
        "        # limit을 초과해서 가져왔을 수 있으므로 정확히 limit 개수만큼만 잘라냅니다.\n",
        "        limited_video_ids = video_ids[:limit]\n",
        "\n",
        "        all_videos = []\n",
        "        for i in range(0, len(limited_video_ids), 50):\n",
        "            videos_response = youtube.videos().list(\n",
        "                part='snippet,statistics,contentDetails',\n",
        "                id=','.join(limited_video_ids[i:i+50])\n",
        "            ).execute()\n",
        "            all_videos.extend(videos_response['items'])\n",
        "\n",
        "        return all_videos\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"데이터 수집 중 에러 발생: {e}\")\n",
        "        return []\n",
        "\n",
        "def analyze_channel_videos(videos, sort_by='popular', start_date=None, end_date=None, limit=MAX_VIDEOS):\n",
        "    \"\"\"\n",
        "    가져온 동영상 리스트를 주어진 조건에 따라 필터링하고 정렬합니다.\n",
        "\n",
        "    Args:\n",
        "        videos (list): 분석할 전체 동영상 리스트\n",
        "        sort_by (str): 'popular' (인기순), 'latest' (최신순) 중 하나\n",
        "        start_date (str): 'YYYY-MM-DD' 형식의 시작 날짜\n",
        "        end_date (str): 'YYYY-MM-DD' 형식의 종료 날짜\n",
        "\n",
        "    Returns:\n",
        "        list: 조건에 맞게 처리된 동영상 리스트\n",
        "    \"\"\"\n",
        "    processed_videos = videos\n",
        "\n",
        "    # 1. 날짜 필터링\n",
        "    if start_date and end_date:\n",
        "        start_dt = datetime.fromisoformat(start_date + 'T00:00:00Z')\n",
        "        end_dt = datetime.fromisoformat(end_date + 'T23:59:59Z')\n",
        "        processed_videos = [\n",
        "            v for v in processed_videos\n",
        "            if start_dt <= datetime.fromisoformat(v['snippet']['publishedAt'].replace('Z', '+00:00')) <= end_dt\n",
        "        ]\n",
        "\n",
        "    # 2. 정렬\n",
        "    if sort_by == 'popular':\n",
        "        processed_videos = sorted(\n",
        "            processed_videos,\n",
        "            key=lambda v: int(v['statistics'].get('viewCount', 0)),\n",
        "            reverse=True\n",
        "        )\n",
        "    elif sort_by == 'latest':\n",
        "        processed_videos = sorted(\n",
        "            processed_videos,\n",
        "            key=lambda v: v['snippet']['publishedAt'],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "    return processed_videos[:limit]\n",
        "\n",
        "def convert_dataframe_from_video_data(videos):\n",
        "  videos_data = []\n",
        "  for video in videos:\n",
        "    video_data = {\n",
        "        \"video_id\": video.get(\"id\"),\n",
        "        \"title\": video.get(\"snippet\").get(\"title\"),\n",
        "        \"channel_title\": video.get(\"snippet\").get(\"channelTitle\"),\n",
        "        \"upload_date\": video.get(\"snippet\").get(\"publishedAt\"),\n",
        "        \"view_count\": video.get(\"statistics\").get(\"viewCount\"),\n",
        "        \"like_count\": video.get(\"statistics\").get(\"likeCount\"),\n",
        "        \"comment_count\": video.get(\"statistics\").get(\"commentCount\"),\n",
        "        \"duration\": video.get(\"contentDetails\").get(\"duration\"),\n",
        "        \"description\": video.get(\"snippet\").get(\"description\"),\n",
        "        \"collected_at\": datetime.now().isoformat()\n",
        "    }\n",
        "    videos_data.append(video_data)\n",
        "\n",
        "  videos_df = pd.DataFrame(videos_data)\n",
        "  return videos_df\n",
        "\n",
        "def collect_video_comments(videos_df, youtube=youtube, max_comments_per_video=MAX_COMMENTS_PER_VIDEO):\n",
        "    \"\"\"\n",
        "    주어진 동영상 목록(DataFrame)에 대해 댓글을 수집하여 DataFrame으로 반환합니다.\n",
        "\n",
        "    Args:\n",
        "        youtube: YouTube API 서비스 객체\n",
        "        videos_df (pd.DataFrame): 'video_id', 'title' 컬럼을 포함한 데이터프레임\n",
        "        max_comments_per_video (int): 영상당 수집할 최대 댓글 수\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 수집된 모든 댓글 정보가 담긴 데이터프레임\n",
        "    \"\"\"\n",
        "    if videos_df.empty:\n",
        "        print(\"분석할 영상이 없어 댓글 수집을 건너뜁니다.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    all_comments = []\n",
        "    print(\"\\n=================================================================\")\n",
        "    print(\"영상 댓글 수집 시작\")\n",
        "    print(\"=================================================================\")\n",
        "\n",
        "    for idx, video in videos_df.iterrows():\n",
        "        video_id = video['video_id']\n",
        "        video_title = video['title']\n",
        "        print(f\"\\n[{idx+1}/{len(videos_df)}] '{video_title[:40]}...' 댓글 수집 중...\")\n",
        "\n",
        "        try:\n",
        "            comments_request = youtube.commentThreads().list(\n",
        "                part='snippet',\n",
        "                videoId=video_id,\n",
        "                maxResults=max_comments_per_video,\n",
        "                order='relevance'  # 인기순 (또는 'time'으로 최신순)\n",
        "            )\n",
        "            comments_response = comments_request.execute()\n",
        "\n",
        "            video_comments = []\n",
        "            for item in comments_response['items']:\n",
        "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "                comment_data = {\n",
        "                    'video_id': video_id,\n",
        "                    'video_title': video_title,\n",
        "                    'comment_id': item['snippet']['topLevelComment']['id'],\n",
        "                    'text': top_comment['textDisplay'],\n",
        "                    'author': top_comment['authorDisplayName'],\n",
        "                    'like_count': top_comment.get('likeCount', 0),\n",
        "                    'published_at': top_comment['publishedAt'],\n",
        "                    'reply_count': item['snippet'].get('totalReplyCount', 0),\n",
        "                    'collected_at': datetime.now().isoformat()\n",
        "                }\n",
        "                video_comments.append(comment_data)\n",
        "\n",
        "            all_comments.extend(video_comments)\n",
        "            print(f\"  ✅ {len(video_comments)}개 댓글 수집 완료\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        except HttpError as e:\n",
        "            error_message = str(e)\n",
        "            if 'commentsDisabled' in error_message:\n",
        "                print(\"  ⚠️ 댓글이 비활성화된 영상입니다.\")\n",
        "            elif 'quotaExceeded' in error_message:\n",
        "                print(\"  🛑 API 사용량 초과! 댓글 수집을 중단합니다.\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"  ❌ API 오류: {error_message}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ 댓글 수집 중 알 수 없는 오류: {e}\")\n",
        "\n",
        "    print(f\"\\n댓글 수집 완료! 총 {len(all_comments)}개 댓글 수집\")\n",
        "    return pd.DataFrame(all_comments)\n",
        "\n",
        "def preprocess_comments(comments_df):\n",
        "    \"\"\"\n",
        "    댓글 데이터프레임을 받아 기본적인 전처리를 수행합니다.\n",
        "\n",
        "    Args:\n",
        "        comments_df (pd.DataFrame): 원본 댓글 데이터프레임\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 필요한 컬럼만 선택하고 텍스트의 양끝 공백을 제거한 데이터프레임\n",
        "    \"\"\"\n",
        "    if comments_df.empty:\n",
        "        print(\"댓글 데이터가 없어 데이터 정리를 건너뜁니다.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # 필요한 컬럼만 선택하여 새로운 데이터프레임 생성\n",
        "    processed_df = comments_df[[\n",
        "        'text', 'author', 'like_count', 'video_title'\n",
        "    ]].copy()\n",
        "\n",
        "    # 'text' 컬럼의 양쪽 끝 공백 제거 (효율적인 pandas 방식)\n",
        "    processed_df['text'] = processed_df['text'].str.strip()\n",
        "\n",
        "    print(f\"총 {len(processed_df)}개의 댓글 처리 완료!\")\n",
        "    return processed_df\n",
        "\n",
        "def generate_and_save_ai_report(\n",
        "    genai_client,\n",
        "    videos_df,\n",
        "    comments_df,\n",
        "    meaningful_comments,\n",
        "    channel_name,\n",
        "    prompt,\n",
        "    save_path=SAVE_PATH,\n",
        "    model_name=\"gemini-2.0-flash\"\n",
        "):\n",
        "    \"\"\"\n",
        "    영상과 댓글 데이터를 기반으로 AI 분석 리포트를 생성하고 파일로 저장합니다.\n",
        "\n",
        "    Args:\n",
        "        genai_client: Gemini AI 클라이언트 객체\n",
        "        model_name (str): 사용할 Gemini 모델 이름 (예: 'gemini-1.5-flash')\n",
        "        videos_df (pd.DataFrame): 분석할 영상 정보 데이터프레임\n",
        "        comments_df (pd.DataFrame): 전체 댓글 데이터프레임 (통계용)\n",
        "        meaningful_comments (list): AI에게 전달할 주요 댓글 리스트\n",
        "        channel_name (str): 분석할 채널의 이름\n",
        "        view_threshold (int): 분석 조건에 명시할 조회수 기준\n",
        "        save_path (str): 분석 리포트 파일을 저장할 경로\n",
        "\n",
        "    Returns:\n",
        "        str: 저장된 파일의 경로. 실패 시 None 반환.\n",
        "    \"\"\"\n",
        "    if videos_df.empty or comments_df.empty:\n",
        "        print(\"영상 또는 댓글 데이터가 부족하여 AI 분석을 건너뜁니다.\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\n=================================================================\")\n",
        "    print(\" AI 분석 리포트 생성 시작\")\n",
        "    print(\"=================================================================\")\n",
        "    print(\"AI 분석용 데이터 준비 중...\")\n",
        "\n",
        "    # 영상 정보를 텍스트로 정리\n",
        "    video_summary = []\n",
        "    for _, video in videos_df.iterrows():\n",
        "        summary = f\"\"\"제목: {video['title']}\n",
        "조회수: {video['view_count']:}회\n",
        "좋아요: {video['like_count']:}개\n",
        "댓글: {video['comment_count']:}개\n",
        "업로드: {video['upload_date']}\n",
        "재생시간: {video['duration']}\"\"\"\n",
        "        video_summary.append(summary)\n",
        "    videos_text = '\\n\\n'.join(video_summary)\n",
        "\n",
        "    # 댓글 정보를 텍스트로 정리\n",
        "    comments_for_ai = []\n",
        "\n",
        "    for _, comment in meaningful_comments.iterrows():\n",
        "      # 댓글을 읽기 쉽게 정리\n",
        "      comment_line = f\"[{comment['like_count']} LIKES ] {comment['author']}: {comment['text']}\"\n",
        "      comments_for_ai.append(comment_line)\n",
        "    # AI에게 분석을 요청할 프롬프트 작성\n",
        "    analysis_prompt = f\"\"\"YouTube 채널 '{channel_name}' 분석 데이터입니다.\n",
        "방송 PD와 콘텐츠 기획자를 위한 실용적인 분석을 해주세요.\n",
        "\n",
        "=== 분석 대상 ===\n",
        "채널: {channel_name}\n",
        "\n",
        "=== 인기 영상 성과 ===\n",
        "{videos_text}\n",
        "\n",
        "=== 시청자 댓글 반응 (댓글 좋아요 순) ===\n",
        "{comments_for_ai}\n",
        "\n",
        "{prompt}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        print(f\"AI 분석 요청 중... (모델: {model_name})\")\n",
        "        response = genai_client.models.generate_content(\n",
        "            model=model_name, # 모델 이름 형식에 맞게 수정\n",
        "            contents=analysis_prompt\n",
        "        )\n",
        "        ai_analysis = response.text\n",
        "\n",
        "        print(\"✅ AI 분석 완료!\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"AI 분석 결과\")\n",
        "        print(\"=\"*60)\n",
        "        print(ai_analysis)\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # AI 분석 결과를 파일로 저장\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        analysis_filename = f\"ai_analysis_{channel_name}_{timestamp}.txt\"\n",
        "        analysis_path = os.path.join(save_path, analysis_filename)\n",
        "\n",
        "        with open(analysis_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"=== {channel_name} AI 분석 리포트 ===\\n\")\n",
        "            f.write(f\"분석 일시: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"분석 영상: {len(videos_df)}개\\n\")\n",
        "            f.write(f\"분석 댓글: {len(comments_df)}개\\n\")\n",
        "            f.write(f\"AI 전달 댓글: {len(meaningful_comments)}개\\n\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\")\n",
        "            f.write(ai_analysis)\n",
        "\n",
        "        print(f\"\\n✅ AI 분석 결과 저장 완료: {analysis_path}\")\n",
        "        return analysis_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ AI 분석 중 오류 발생: {e}\")\n",
        "        print(\"API 키를 확인하거나 나중에 다시 시도해주세요.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def retrieve_channel_videos(channel_name,  sort_by='popular', start_date=None, end_date=None, limit=MAX_VIDEOS):\n",
        "  \"\"\"\n",
        "  유튜브 데이터 API를 활용하여 비디오 데이터를 수집합니다.\n",
        "  Args:\n",
        "      channel_name (str): 분석할 채널의 이름\n",
        "      sort_by (str): 'popular' (인기순), 'latest' (최신순) 중 하나\n",
        "      start_date (str): 'YYYY-MM-DD' 형식의 시작 날짜\n",
        "      end_date (str): 'YYYY-MM-DD' 형식의 종료 날짜\n",
        "      limit (int): 가져올 비디오 개수\n",
        "\n",
        "  Returns:\n",
        "      pd.DataFrame: 수집된 비디오 정보가 담긴 데이터프레임\n",
        "  \"\"\"\n",
        "  channel_id = get_channel_id_by_handle(channel_name)\n",
        "  videos = get_all_channel_videos(youtube, channel_id)\n",
        "  videos = analyze_channel_videos(videos, sort_by, start_date, end_date, limit)\n",
        "  videos_df = convert_dataframe_from_video_data(videos)\n",
        "  return videos_df\n",
        "\n",
        "def save_raw_data(videos_df, comments_df):\n",
        "  \"\"\"\n",
        "  수집한 비디오 및 댓글 데이터를 구글 드라이브에 저장합니다.\n",
        "\n",
        "   Args:\n",
        "        videos_df: 비디오의 데이터프레임\n",
        "        comments_df: 댓글의 데이터프레임\n",
        "  \"\"\"\n",
        "  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "  if not videos_df.empty:\n",
        "    video_filename = f\"videos_{timestamp}.csv\"\n",
        "    video_path = os.path.join(SAVE_PATH, video_filename)\n",
        "    # 한글이 깨지지 않도록 utf-8-sig 인코딩 사용\n",
        "    videos_df.to_csv(video_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"영상 데이터 저장: {video_filename}\")\n",
        "\n",
        "  # 댓글 정보 저장 (CSV 파일로)\n",
        "  if not comments_df.empty:\n",
        "      comments_filename = f\"comments_{timestamp}.csv\"\n",
        "      comments_path = os.path.join(SAVE_PATH, comments_filename)\n",
        "      comments_df.to_csv(comments_path, index=False, encoding='utf-8-sig')\n",
        "      print(f\"댓글 데이터 저장: {comments_filename}\")\n",
        "\n",
        "  print(f\"저장 완료! 파일 위치: {SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "S-W-OuLcuGAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "=== 분석 요청사항 ===\n",
        "다음 관점에서 분석해주세요:\n",
        "1. 현재 인기 영상의 성공 요인 (제목 패턴, 영상 길이, 콘텐츠 스타일)\n",
        "2. 댓글을 통한 시청자 반응 분석 (만족도, 주요 관심사, 긍정/부정 의견)\n",
        "3. 실행 가능한 콘텐츠 전략 제안 (기획 아이디어 3가지, 참여도 증진 방안)\n",
        "4. 주의사항 및 개선점\n",
        "\n",
        "방송 현업에서 바로 쓸 수 있는 구체적이고 실용적인 조언을 한국어로 해주세요.\n",
        "댓글 내용을 근거로 구체적인 예시를 들어 설명해주세요.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7oVhYND041LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_name = \"@syukaworld\" #분석하고자 하는 채널 이름\n",
        "sort_by = \"latest\" # 비디오 정렬 방법 latest, popular\n",
        "start_date = None # 필터 시작 날짜, 예: 2025-09-01\n",
        "end_date = None # 필터 끝 날짜, 예: 2025-09-18\n",
        "num_videos_to_analyze = 10 #분석하고자 하는 비디오 개수\n",
        "max_comments_per_video = 20 # 수집할 비디오 당 댓글 개수\n",
        "model_name = \"gemini-2.5-flash\" #제미나이 모델\n",
        "\n",
        "#videos_df = retrieve_channel_videos(channel_name,sort_by=sort_by, start_date=start_date, end_date=end_date, limit=num_videos_to_analyze)\n",
        "#comments_df = collect_video_comments(videos_df, max_comments_per_video=max_comments_per_video)\n",
        "#save_raw_data(videos_df, comments_df)\n",
        "#meaningful_comments = preprocess_comments(comments_df)\n",
        "#generate_and_save_ai_report(genai_client, videos_df, comments_df, meaningful_comments, channel_name, prompt, model_name=model_name)"
      ],
      "metadata": {
        "id": "jSQZ8PVyyD8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}