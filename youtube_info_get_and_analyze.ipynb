{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkcb2hGqPQarMWiGGkuZNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mindong-dost/ai_data_analyzie_course/blob/main/youtube_info_get_and_analyze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 지난 시간 복습"
      ],
      "metadata": {
        "id": "apiVa5ZuWiMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# python 기본 문법\n",
        "print(\"Hello World!\")\n",
        "\n",
        "\n",
        "# python 사칙연산\n",
        "print(1+2, 2*2, 2/2, 3%2, 3**2)\n",
        "\n",
        "\n",
        "# python 변수\n",
        "favorite_number = 7\n",
        "print(favorite_number)\n",
        "\n",
        "\n",
        "# python 변수 : LIST\n",
        "summer_fruit_list = [\"수박\", \"참외\", \"복숭아\"]\n",
        "print(summer_fruit_list)\n",
        "\n",
        "\n",
        "# 조건문\n",
        "if len(summer_fruit_list) > 4:\n",
        "  print('여름과일은 많다')\n",
        "elif len(summer_fruit_list) == 4:\n",
        "  print('여름과일은 딱 4개')\n",
        "else:\n",
        "  print('여름과일은 몇개인가?')\n",
        "  print(len(summer_fruit_list))\n",
        "\n",
        "\n",
        "# 반복문\n",
        "for fruit in summer_fruit_list:\n",
        "  print(fruit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhqGWDOIWmDn",
        "outputId": "8a200fa0-512b-4b51-f990-1d37ae16226d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n",
            "3 4 1.0 1 9\n",
            "7\n",
            "['수박', '참외', '복숭아']\n",
            "여름과일은 몇개인가?\n",
            "3\n",
            "수박\n",
            "참외\n",
            "복숭아\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One More Thing..\n",
        "\n",
        "- try except 구문: 예외 처리 사용하기. 예외(exception)는 말그대로 코드 실행 중 발생한 에러\n",
        "\n",
        "```python\n",
        "try:\n",
        "    실행할 코드\n",
        "except:\n",
        "    예외가 발생했을 때 처리하는 코드"
      ],
      "metadata": {
        "id": "Nd4bOwRZnVrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오늘 배울 내용:\n",
        "\n",
        "---\n",
        "\n",
        "1. 1단계 (50분): 라이브러리 설치 및 환경 설정\n",
        "2. 2단계 (50분): 인기 영상 정보 수집 (yt-dlp 활용)\n",
        "3. 3단계 (45분): 댓글 수집 (YouTube Data API 활용)\n",
        "4. 4단계 (15분): 데이터 저장 및 정리\n",
        "5. 5단계 (50분): AI 분석 리포트 생성 (Google Gemini)\n",
        "\n",
        "\n",
        "# 실습 목표:\n",
        "---\n",
        "\n",
        "- YouTube 채널의 인기 영상과 댓글 데이터를 자동으로 수집\n",
        "- 수집한 데이터를 AI로 분석해서 콘텐츠 전략 도출\n",
        "- 방송 기획에 바로 활용할 수 있는 인사이트 획득\n",
        "\n",
        "\n",
        "#  실습 전 준비사항:\n",
        "---\n",
        "\n",
        "1. YouTube Data API 키 (무료, https://console.cloud.google.com/)\n",
        "2. Google Gemini API 키 (무료, https://aistudio.google.com/)\n",
        "3. 분석하고 싶은 YouTube 채널명 (예: @도프프스튜디오)"
      ],
      "metadata": {
        "id": "WfdRa-3wX--U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API란 무엇인인가?\n",
        "![API설명](https://blog.kakaocdn.net/dna/dqh0Z1/btsIQva8H0p/AAAAAAAAAAAAAAAAAAAAANf_fQ_OcualDAMDI1nKKXY5yzRHT3Cr-rQbGQj_Y03y/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=QZmkSnlJnq6Oh7ytZatp6zZGVIQ%3D)\n",
        "\n",
        "- API(Application Programming Interface)는 소프트웨어 애플리케이션 간의 상호 작용을 가능하게 하는 인터페이스입니다.\n",
        "API는 다양한 기능을 다른 프로그램에서 사용할 수 있도록 정의된 규칙 및 도구의 집합을 제공합니다.\n",
        "출처: https://juntcom.tistory.com/311 [쏘니의 개발블로그:티스토리]\n",
        "\n",
        "---\n",
        "\n",
        "# 파이썬에서 함수, 모듈, 패키지, 라이브러리 란 무엇인가?\n",
        "\n",
        "1. 함수 (Function): 함수는 특정 작업을 수행하는 코드의 집합\n",
        "2. 모듈 (Module): 모듈은 파이썬 파일(.py) 하나에 정의된 함수, 클래스, 변수 등을 모아둔 것\n",
        "3. 패키지 (Package): 패키지는 여러 모듈을 디렉토리 구조로 묶어 관리하는 것\n",
        "4. 라이브러리 (Library): 라이브러리는 여러 모듈이나 패키지를 모아둔 일종의 도구 상자\n",
        "\n",
        "---\n",
        "\n",
        "# 파이썬의 철학\n",
        "\n",
        "> 바퀴를 다시 발명하지 마라\n",
        "\n",
        "- 없으면 만들겠지만, 잘 만든 것이 있다면 가져다 쓰자! (+감사하는 마음과)\n",
        "\n",
        "![바퀴를 재발명하지 마라](https://miro.medium.com/v2/resize:fit:492/1*4WpIB7SzfGwfRIlbP_7u6Q.png)"
      ],
      "metadata": {
        "id": "AIv4BGuaklzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1일차 실습: 분석 환경 설정 및 연장 챙기기 (1단계)\n",
        "---\n",
        "\n",
        "## 1단계 목표:\n",
        "본격적인 유튜브 채널 분석에 앞서, 우리의 Colab를 **'데이터 분석 전문가'**로 만들어주는 가장 중요한 준비 단계입니다. 최고의 요리를 위해 최고의 주방 도구를 준비하듯, 정확하고 깊이 있는 분석을 위해 필요한 전문 프로그램들을 설치하고, 유튜브와 AI 서버에 연결하는 과정을 진행합니다.\n",
        "\n",
        "## 이번 단계 실습 내용:\n",
        "1.  **필수 프로그램(라이브러리) 설치하기:** 파이썬의 '앱 스토어'(`pip`)를 이용해 데이터 수집, 정리, AI 분석에 필요한 전문가용 도구들을 컴퓨터에 설치합니다.\n",
        "2.  **API 키 연결 및 설정하기:** 유튜브와 AI의 데이터 창구에 접속할 수 있는 **'비밀 열쇠(API 키)'**를 우리 프로그램에 등록합니다. 이 열쇠가 있어야 공식적이고 정확한 데이터를 받아올 수 있습니다.\n",
        "3.  **구글 드라이브 연결하기:** 오늘 우리가 분석하고 만들어낼 모든 결과물(엑셀 파일, 분석 리포트 등)이 사라지지 않고 **나의 구글 드라이브에 안전하게 저장**되도록 경로를 터주는 작업입니다.\n",
        "\n",
        "## 주요 라이브러리 (핵심 도구) 소개:\n",
        "-   **`yt-dlp` (꼼꼼한 데이터 수집가):** 유튜브 영상의 제목, 조회수, 길이 등 겉으로 보이는 기본 정보들을 가장 빠르고 안정적으로 긁어오는 전문가입니다.\n",
        "-   **`google-api-client` (유튜브 공식 통역사):** 댓글, 좋아요 수처럼 유튜브 내부에 기록된 상세 데이터에 접근할 수 있도록 구글과 직접 소통하게 해주는 공식 창구입니다.\n",
        "-   **`google-genai` (천재 AI 분석가, 제미나이):** 우리가 수집하고 정리한 데이터를 넘겨주면, 방송 PD의 관점에서 날카로운 인사이트와 콘텐츠 전략을 담은 보고서를 작성해주는 인공지능입니다.\n",
        "-   **`pandas` (데이터 정리의 달인):** 어지럽게 수집된 데이터를 우리가 보기 편한 엑셀 표(DataFrame) 형태로 깔끔하게 정리하고, 계산하고, 가공하는 데 꼭 필요한 최고의 도구입니다.\n",
        "-   **`matplotlib` (데이터 시각화 예술가):** 딱딱한 숫자 데이터를 한눈에 파악하기 쉬운 멋진 그래프로 변신시켜주는 도구입니다.\n",
        "\n",
        "---\n",
        "## 예상 소요시간 및 주의사항:\n",
        "\n",
        "-   **예상 소요시간:** 약 10~15분 (인터넷 속도나 컴퓨터 환경에 따라 조금씩 다를 수 있습니다.)\n",
        "-   **주의사항:**\n",
        "    -   설치 과정 중 빨간색 글씨로 경고 메시지가 나타날 수 있지만, 대부분은 사소한 알림이므로 마지막에 'Successfully installed...' 문구가 보이면 정상입니다.\n",
        "    -   API 키는 외부로 유출되면 안 되는 중요한 개인 정보입니다. 코드에 붙여넣은 후에는 다른 사람에게 공유하지 않도록 주의해주세요.\n",
        "    -   구글 드라이브 연결 시, 구글 계정으로 로그인하고 접근 권한을 허용하는 팝업창이 나타나면 승인해주셔야 합니다.\n",
        "\n",
        "---\n",
        "## 왜 이 도구들을 선택했나요? (PD님을 위한 TMI)\n",
        "\n",
        "1.  **`yt-dlp`를 쓰는 이유:** 유튜브의 정책이나 구조가 바뀌어도 가장 발 빠르게 대응하여 안정적으로 데이터를 가져옵니다. 불필요한 로그인 절차 없이 공개된 정보를 가장 확실하게 수집하는 최고의 선택입니다.\n",
        "2.  **`YouTube Data API`를 쓰는 이유:** 구글이 직접 제공하는 '공식' 데이터 파이프라인입니다. 따라서 댓글, 좋아요 수 등 채널의 민감한 상호작용 데이터를 가장 정확하고 신뢰할 수 있는 방법으로 얻을 수 있습니다. 하루에 수백 개 이상의 영상을 분석할 수 있는 넉넉한 무료 사용량을 제공합니다.\n",
        "3.  **`Google Gemini`를 쓰는 이유:** 최신 AI 모델로서, 단순한 데이터 요약을 넘어 **'실행 가능한 전략(Actionable Insight)'을 제시**하는 데 매우 뛰어납니다. 우리가 전달한 댓글 내용을 근거로 매우 구체적인 분석과 아이디어를 제공해줍니다."
      ],
      "metadata": {
        "id": "T01oS1Vin8dM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMQCcz1GXwAf",
        "outputId": "aab22664-1391-471e-eeb0-7e28a271ad69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.9.5-py3-none-any.whl.metadata (177 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m174.1/177.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.181.0)\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.34.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.12/dist-packages (1.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.30.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.10.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from wordcloud) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from wordcloud) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Downloading yt_dlp-2025.9.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.9.5\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =================================================================\n",
        "# 방송 PD용 YouTube 데이터 수집 및 분석기 - 1일차 실습 (4시간)\n",
        "# yt-dlp + YouTube Data API + Gemini AI 기본 활용\n",
        "# Google Colab 환경에서 실행\n",
        "# =================================================================\n",
        "\n",
        "# 필요한 라이브러리를 모두 설치합니다 (한번만 실행)\n",
        "!pip install yt-dlp google-api-python-client google-genai wordcloud\n",
        "\n",
        "# 필요한 모든 라이브러리를 한번에 불러옵니다\n",
        "import os                      # 파일과 폴더 관리용\n",
        "import json                    # JSON 데이터 처리용\n",
        "import time                    # 시간 지연용\n",
        "import pandas as pd            # 데이터 분석용 (엑셀과 비슷)\n",
        "import matplotlib.pyplot as plt # 그래프 그리기용\n",
        "import numpy as np             # 수학 계산용\n",
        "from collections import Counter # 빈도 계산용\n",
        "import re                      # 텍스트 처리용\n",
        "from datetime import datetime, timedelta  # 날짜 계산용\n",
        "import subprocess              # 외부 프로그램 실행용\n",
        "\n",
        "\n",
        "# Google Drive를 연결합니다 (결과 저장용)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# YouTube 데이터를 가져오는 라이브러리\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "\n",
        "# AI 분석용 라이브러리\n",
        "from google import genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 단계는 우리가 만들 분석기의 **'조종석(Control Panel)'**을 설정하는 가장 중요한 과정입니다. 어떤 채널을 분석할지, 어떤 기준으로 데이터를 가져올지 등 **분석의 방향을 결정**하고, 유튜브와 AI 서버로 연결되는 **데이터 고속도로를 개통**하는 작업을 진행합니다.\n",
        "\n",
        "## 이번 단계 실습 내용:\n",
        "\n",
        "### 1. 사용자 설정: 나만의 분석기 만들기\n",
        "이 영역은 PD님께서 직접 분석 조건을 입력하는 **유일한 공간**입니다. 마치 내비게이션에 목적지와 경유지를 설정하듯, 여기에 입력하는 값에 따라 분석 결과가 완전히 달라집니다.\n",
        "\n",
        "-   **`API_KEY` (비밀 통행증 발급):**\n",
        "    -   **역할:** 유튜브와 AI 서버의 데이터 센터에 접속하기 위한 **'비밀 인증키'**입니다. 이 키가 있어야 구글이 \"아, 허가된 사용자구나\"라고 인식하고 데이터를 내어줍니다.\n",
        "    -   **설정 방법:** 미리 발급받은 2개의 긴 문자열(유튜브용, 제미나이용)을 각각 따옴표 안에 붙여넣어 주세요.\n",
        "\n",
        "-   **`CHANNEL_NAME` (분석 대상 채널 지정):**\n",
        "    -   **역할:** 오늘 분석하고 싶은 유튜브 채널의 고유 주소(@로 시작하는)를 지정합니다.\n",
        "    -   **설정 방법:** 따옴표 안에 분석할 채널의 `@이름`을 정확하게 입력합니다. (예: `\"@도프프스튜디오\"`)\n",
        "\n",
        "-   **`VIEW_THRESHOLD` (영상 선별 기준 설정):**\n",
        "    -   **역할:** \"최소 이 정도 조회수는 넘는 영상들만 분석해줘!\"라고 기준을 정해주는 **'인기 영상 필터'**입니다. 어뷰징이나 반응이 적은 영상을 제외하고 의미 있는 데이터만 보기 위함입니다.\n",
        "    -   **설정 방법:** `100000`은 '10만 회'를 의미합니다. 채널 규모에 맞게 숫자를 조절할 수 있습니다.\n",
        "\n",
        "-   **`MAX_VIDEOS` / `MAX_COMMENTS_PER_VIDEO` (데이터 수집량 조절):**\n",
        "    -   **역할:** 분석 시간과 비용(API 사용량)을 조절하는 **'수도꼭지'** 역할을 합니다. 너무 많은 데이터를 한 번에 요청하면 시간이 오래 걸리고 API 할당량을 초과할 수 있습니다.\n",
        "    -   **설정 방법:** `MAX_VIDEOS = 10`은 '인기 영상 10개', `MAX_COMMENTS_PER_VIDEO = 20`은 '영상 1개당 댓글 20개'를 의미합니다. 처음에는 적은 수로 테스트하고 점차 늘려가는 것을 추천합니다.\n",
        "\n",
        "-   **`SAVE_PATH` (결과물 보관 장소 지정):**\n",
        "    -   **역할:** 분석을 통해 만들어질 모든 결과 파일(엑셀, 리포트 등)이 저장될 **'개인 서랍장(폴더)'** 주소를 지정합니다.\n",
        "    -   **설정 방법:** 기본 설정 그대로 두시면 구글 드라이브 내 `youtube_analysis` 폴더에 저장되며, 폴더가 없으면 코드가 알아서 척척 만들어주니 걱정하지 않으셔도 됩니다.\n",
        "\n",
        "### 2. API 연결: 데이터 고속도로 개통\n",
        "이 코드는 PD님께서 직접 수정할 필요가 없는 **'엔진룸'**입니다. 위에서 설정한 비밀 통행증(API 키)을 이용해 유튜브와 AI 서버에 실제로 전화를 걸어 연결을 시도하고, 성공 여부를 알려주는 역할을 합니다.\n",
        "\n",
        "-   `try...except` 구문의 역할 (똑똑한 안전장치):\n",
        "    -   `try`: 일단 연결을 **시도해 본다!**\n",
        "    -   `except`: 만약 연결에 **실패하면**(API 키가 틀렸거나, 인터넷 문제 등), 프로그램을 멈추지 않고 \"연결에 실패했습니다. API 키를 확인해주세요\"라는 **친절한 안내 메시지**를 보여줍니다. 코드가 갑자기 고장 나지 않도록 보호하는 안전장치입니다.\n",
        "\n",
        "성공적으로 연결되면 \"YouTube API 연결 성공!\", \"Gemini AI 연결 성공!\"이라는 메시지가 출력되며, 이제 우리는 데이터를 수집하고 분석할 모든 준비를 마치게 됩니다."
      ],
      "metadata": {
        "id": "DI4a-tn7tbk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 사용자 설정 부분 - 여기만 수정하면 됩니다!\n",
        "# =================================================================\n",
        "\n",
        "# API 키 설정 (실제 키로 바꿔주세요)\n",
        "YOUTUBE_API_KEY = \"발급받은 유튜브 API 키\"  # YouTube Data API 키\n",
        "GEMINI_API_KEY = \"발급받은 제미나이 API 키\"    # Gemini AI 키\n",
        "\n",
        "# 분석하고 싶은 채널 설정\n",
        "CHANNEL_NAME = \"@채널이름\"  # 예: \"@도프프스튜디오\" 같은 형태\n",
        "\n",
        "# 분석 조건 설정\n",
        "VIEW_THRESHOLD = 100000     # 최소 조회수 (10만회 이상만 분석)\n",
        "MAX_VIDEOS = 10             # 분석할 영상 개수 (10개)\n",
        "MAX_COMMENTS_PER_VIDEO = 20 # 영상당 댓글 개수 (20개)\n",
        "\n",
        "# 결과 저장할 폴더 설정\n",
        "SAVE_PATH = \"/content/drive/MyDrive/youtube_analysis/\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)  # 폴더가 없으면 자동 생성\n",
        "\n",
        "print(\"설정 완료!\")\n",
        "print(f\"분석 채널: {CHANNEL_NAME}\")\n",
        "print(f\"최소 조회수: {VIEW_THRESHOLD:,}회\")\n",
        "print(f\"저장 위치: {SAVE_PATH}\")\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# API 연결 설정\n",
        "# =================================================================\n",
        "\n",
        "# YouTube Data API 연결\n",
        "try:\n",
        "    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
        "    print(\"YouTube API 연결 성공!\")\n",
        "except Exception as e:\n",
        "    print(f\"YouTube API 연결 실패: {e}\")\n",
        "    print(\"API 키를 확인해주세요\")\n",
        "\n",
        "# Gemini AI 연결\n",
        "try:\n",
        "    os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "    genai_client = genai.Client()\n",
        "    print(\"Gemini AI 연결 성공!\")\n",
        "except Exception as e:\n",
        "    print(f\"Gemini AI 연결 실패: {e}\")\n",
        "    print(\"API 키를 확인해주세요\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GexR0vnwYTme",
        "outputId": "e80b437b-441d-404e-cae5-2649f6057697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "설정 완료!\n",
            "분석 채널: @Moneygraphy\n",
            "최소 조회수: 100,000회\n",
            "저장 위치: /content/drive/MyDrive/youtube_analysis/\n",
            "YouTube API 연결 성공!\n",
            "Gemini AI 연결 성공!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1단계에서 배우는 핵심 내용: 인기 영상 탐색 및 기본 정보 수집 (1단계)\n",
        "---\n",
        "\n",
        "## 1단계 목표:\n",
        "이제 본격적인 데이터 수집의 첫발을 내딛습니다. 이번 단계의 목표는 우리가 지정한 채널에서 **'가장 성공적인 영상', 즉 보석 같은 콘텐츠들을 찾아내고, 그 기본 정보(이력서)를 확보**하는 것입니다. 마치 유능한 스카우터가 수많은 선수들의 기록을 훑어보고, 가장 뛰어난 선수 몇 명의 프로필을 추려내는 과정과 같습니다.\n",
        "\n",
        "## 이번 단계 실습 내용: \"yt-dlp 스카우터\"의 2단계 작업 프로세스\n",
        "우리 코드 속의 스카우터(`yt-dlp`)는 매우 효율적으로 일합니다. 무작정 모든 영상을 다 뒤지는 것이 아니라, 다음과 같은 2단계 전략을 사용합니다.\n",
        "\n",
        "### 1차 스캔: 채널 전체 영상 목록 '빠르게 훑어보기'\n",
        "-   **작업 내용:** 먼저 채널에 있는 최신 영상 목록을 '제목'과 'ID(주민등록번호)' 중심으로 최대한 빠르게 훑어봅니다. 영상 다운로드나 상세 정보 확인 없이, 목록만 빠르게 확보하여 시간과 자원을 아끼는 과정입니다.\n",
        "-   **코드의 움직임:** `yt-dlp` 로봇에게 `--flat-playlist` (목록만 줘!) 옵션을 주어 채널의 영상 리스트를 신속하게 받아옵니다.\n",
        "\n",
        "### 2차 심층 분석: 인기 영상 '선별' 및 상세 정보 수집\n",
        "-   **작업 내용:** 1차 스캔으로 확보한 목록을 하나씩 확인하면서, 우리가 설정한 **최소 조회수 기준(`VIEW_THRESHOLD`)**을 넘는 '대박 영상'들만 선별합니다. 그리고 선별된 영상에 대해서만 **조회수, 좋아요 수, 영상 길이 등 상세한 프로필(메타데이터)을 꼼꼼하게 수집**합니다.\n",
        "-   **코드의 움직임:**\n",
        "    1.  반복문(`for`)을 통해 영상 ID를 하나씩 꺼내 봅니다.\n",
        "    2.  `if view_count < VIEW_THRESHOLD:` 구문을 통해 조회수가 기준에 미달하는 영상은 \"넌 탈락!\"이라며 과감히 건너뜁니다.\n",
        "    3.  합격한 영상의 정보만 `video_data` 라는 이름의 깔끔한 메모장에 정리하여, 최종 보고서 목록인 `videos_data`에 차곡차곡 추가합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 코드 속 핵심 기능 엿보기 (PD님을 위한 번역기):\n",
        "\n",
        "-   **`yt-dlp` (데이터 수집 전문 로봇):** 유튜브 채널에 접속해서 영상 목록과 상세 정보를 긁어오는 역할을 하는, 매우 빠르고 안정적인 외부 프로그램입니다.\n",
        "-   **`subprocess.run` (로봇 호출 버튼):** 파이썬 코드 안에서 `yt-dlp` 로봇에게 \"지금 바로 이 명령을 실행해!\"라고 작업을 지시하는 버튼입니다.\n",
        "-   **`time.sleep(1)` (매너 있는 기다림):**\n",
        "    -   **이게 왜 중요할까요?** 너무 짧은 시간에 유튜브 서버에 수십, 수백 번 접속하면, 유튜브는 우리를 '공격자(어뷰저)'로 오인하고 일시적으로 접근을 차단할 수 있습니다.\n",
        "    -   **어떻게 동작하나요?** 영상 정보를 하나 수집할 때마다 **의도적으로 1초씩 쉬어주는 '착한 기능'**입니다. \"똑똑, 실례합니다. 정보 하나만 받고 1초 뒤에 다시 올게요\"라고 예의를 지키는 것과 같아서, 차단 위험 없이 안정적으로 데이터를 수집하게 해줍니다.\n",
        "-   **`pd.DataFrame(videos_data)` (최종 보고서 작성):**\n",
        "    -   지금까지 메모장처럼 하나씩 모아온 영상들의 정보(`videos_data`)를, 우리가 한눈에 보기 좋은 **엑셀(Excel) 표 형태로 변환**하는 마법 같은 명령어입니다. 이제 이 표를 `videos_df` 라는 이름으로 부르며, 다음 단계에서 정렬하거나 분석하는 데 사용하게 됩니다.\n",
        "\n",
        "## 최종 결과물:\n",
        "이 모든 과정이 끝나면, 기준을 통과한 **'Target 채널 최고의 인기 영상 목록'**이 엑셀 표(`videos_df`) 형태로 완성됩니다. 이제 우리는 이 영상 목록을 가지고, 다음 단계에서 시청자들의 의견, '댓글'을 수집하러 가고자 합니다."
      ],
      "metadata": {
        "id": "vGtU9UEWp3R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 1단계: 인기 영상 정보 수집하기 (yt-dlp 사용)\n",
        "# =================================================================\n",
        "\n",
        "# 수집된 영상 정보를 저장할 리스트\n",
        "videos_data = []\n",
        "\n",
        "try:\n",
        "    # 1단계: 채널의 영상 목록 가져오기\n",
        "    print(\"채널 영상 목록 가져오는 중...\")\n",
        "\n",
        "    # yt-dlp 명령어 실행 (채널의 영상 목록을 JSON으로 가져오기)\n",
        "    cmd = [\n",
        "        'yt-dlp',                                    # yt-dlp 프로그램 실행\n",
        "        '--flat-playlist',                           # 영상 목록만 가져오기 (다운로드 안함)\n",
        "        '--dump-json',                               # 정보를 JSON 형태로 출력\n",
        "        '--playlist-end', str(MAX_VIDEOS * 2),       # 여유분으로 더 많이 가져오기\n",
        "        f'https://www.youtube.com/{CHANNEL_NAME}/videos'  # 채널 URL\n",
        "    ]\n",
        "\n",
        "    # 명령어 실행 (최대 60초 대기)\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
        "\n",
        "    # 실행 결과 확인\n",
        "    if result.returncode != 0:  # 오류 발생\n",
        "        print(f\"영상 목록 가져오기 실패: {result.stderr}\")\n",
        "    else:\n",
        "        print(\"영상 목록 가져오기 성공!\")\n",
        "\n",
        "        # 결과에서 영상 ID 추출\n",
        "        video_ids = []\n",
        "        for line in result.stdout.strip().split('\\n'):\n",
        "            if line.strip():  # 빈 줄이 아니면\n",
        "                try:\n",
        "                    video_info = json.loads(line)  # JSON으로 변환\n",
        "                    video_id = video_info.get('id', '')  # 영상 ID 추출\n",
        "                    if video_id:\n",
        "                        video_ids.append(video_id)\n",
        "                except:\n",
        "                    continue  # 변환 실패하면 넘어가기\n",
        "\n",
        "        print(f\"찾은 영상 개수: {len(video_ids)}개\")\n",
        "\n",
        "        # 2단계: 각 영상의 상세 정보 가져오기\n",
        "        for i, video_id in enumerate(video_ids):\n",
        "            # 원하는 개수만큼 수집했으면 중단\n",
        "            if len(videos_data) >= MAX_VIDEOS:\n",
        "                break\n",
        "\n",
        "            print(f\"영상 정보 수집 중... [{i+1}/{min(len(video_ids), MAX_VIDEOS*2)}]\")\n",
        "\n",
        "            try:\n",
        "                # 개별 영상 상세 정보 가져오기\n",
        "                detail_cmd = [\n",
        "                    'yt-dlp',\n",
        "                    '--dump-json',           # JSON 정보만 가져오기\n",
        "                    '--skip-download',       # 영상 다운로드 안함\n",
        "                    f'https://www.youtube.com/watch?v={video_id}'  # 영상 URL\n",
        "                ]\n",
        "\n",
        "                # 명령어 실행 (최대 30초 대기)\n",
        "                detail_result = subprocess.run(detail_cmd, capture_output=True, text=True, timeout=30)\n",
        "\n",
        "                if detail_result.returncode == 0:  # 성공\n",
        "                    video_detail = json.loads(detail_result.stdout)  # JSON 변환\n",
        "\n",
        "                    # 업로드 날짜 확인 (분석 기간에 해당하는지 체크)\n",
        "                    upload_date_str = video_detail.get('upload_date', '')\n",
        "\n",
        "                    # 조회수 확인 (기준 미달이면 건너뛰기)\n",
        "                    view_count = video_detail.get('view_count', 0)\n",
        "                    if view_count < VIEW_THRESHOLD:\n",
        "                        print(f\"  조회수 부족: {view_count:,}회\")\n",
        "                        continue\n",
        "\n",
        "                    # 영상 정보 정리해서 저장\n",
        "                    video_data = {\n",
        "                        'video_id': video_detail.get('id', ''),                    # 영상 ID\n",
        "                        'title': video_detail.get('title', ''),                   # 제목\n",
        "                        'channel_title': video_detail.get('uploader', ''),        # 채널명\n",
        "                        'upload_date': upload_date_str,                           # 업로드 날짜\n",
        "                        'view_count': view_count,                                 # 조회수\n",
        "                        'like_count': video_detail.get('like_count', 0),          # 좋아요 수\n",
        "                        'comment_count': video_detail.get('comment_count', 0),    # 댓글 수\n",
        "                        'duration': video_detail.get('duration', 0),             # 재생시간(초)\n",
        "                        'duration_string': video_detail.get('duration_string', ''), # 재생시간(문자)\n",
        "                        'description': video_detail.get('description', '')[:200], # 설명(앞부분만)\n",
        "                        'tags': ','.join(video_detail.get('tags', [])),          # 태그들\n",
        "                        'url': video_detail.get('webpage_url', ''),              # 영상 URL\n",
        "                        'collected_at': datetime.now().isoformat()               # 수집 시간\n",
        "                    }\n",
        "\n",
        "                    videos_data.append(video_data)\n",
        "                    print(f\"  수집 완료: '{video_data['title'][:30]}...' - {view_count:,}회\")\n",
        "\n",
        "                # 서버에 부담 주지 않기 위해 1초 쉬기\n",
        "                time.sleep(1)\n",
        "\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(f\"  시간 초과: {video_id}\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"  오류 발생: {e}\")\n",
        "                continue\n",
        "\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"영상 목록 가져오기 시간 초과\")\n",
        "except Exception as e:\n",
        "    print(f\"영상 정보 수집 중 오류: {e}\")\n",
        "\n",
        "# 수집 결과를 pandas 데이터프레임으로 변환 (엑셀 표와 비슷)\n",
        "videos_df = pd.DataFrame(videos_data)\n",
        "\n",
        "print(f\"\\n수집 완료! 총 {len(videos_df)}개 영상 정보 수집\")\n",
        "\n",
        "# 수집한 영상 목록 출력\n",
        "if not videos_df.empty:\n",
        "    print(\"\\n수집된 영상 목록:\")\n",
        "    for idx, row in videos_df.iterrows():\n",
        "        print(f\"  {idx+1}. {row['title'][:40]}... - {row['view_count']:,}회\")\n",
        "else:\n",
        "    print(\"조건에 맞는 영상이 없습니다.\")\n",
        "    print(f\"(최소 조회수 {VIEW_THRESHOLD:,}회)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFEFLFsDYZRZ",
        "outputId": "f4fb812e-9055-4b53-9906-80e2d28609d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "채널 영상 목록 가져오는 중...\n",
            "영상 목록 가져오기 성공!\n",
            "찾은 영상 개수: 20개\n",
            "영상 정보 수집 중... [1/20]\n",
            "  조회수 부족: 37,017회\n",
            "영상 정보 수집 중... [2/20]\n",
            "  수집 완료: '돈 없으면 살 못 뺀다?! 위고비 시대에 맞이할 다이어...' - 198,336회\n",
            "영상 정보 수집 중... [3/20]\n",
            "  수집 완료: 'AI가 흉내낼 수도 대체할 수도 없는 단 한 가지 (w...' - 247,287회\n",
            "영상 정보 수집 중... [4/20]\n",
            "  조회수 부족: 52,230회\n",
            "영상 정보 수집 중... [5/20]\n",
            "  수집 완료: '비트코인 지금 사야 할까? 트럼프가 가상자산에 진심인 ...' - 163,900회\n",
            "영상 정보 수집 중... [6/20]\n",
            "  조회수 부족: 72,873회\n",
            "영상 정보 수집 중... [7/20]\n",
            "  조회수 부족: 36,303회\n",
            "영상 정보 수집 중... [8/20]\n",
            "  수집 완료: '[최종화] 이 영상은 성지가 됩니다... 떡상 직전 아...' - 163,723회\n",
            "영상 정보 수집 중... [9/20]\n",
            "  수집 완료: '페스티벌에서 관객을 휘어잡는 세 가지 방법 (w. 한로...' - 140,483회\n",
            "영상 정보 수집 중... [10/20]\n",
            "  수집 완료: '“이렇게 해도 케이팝인가요?” 바밍타이거가 말하는 얼터...' - 184,131회\n",
            "영상 정보 수집 중... [11/20]\n",
            "  수집 완료: '좋아하는 게 직업이 될 수 있을까? 음악으로 먹고사는 ...' - 134,228회\n",
            "영상 정보 수집 중... [12/20]\n",
            "  수집 완료: '\"히트곡 공식을 전부 충족한 곡이었어요\" 송소희가 말하...' - 273,629회\n",
            "영상 정보 수집 중... [13/20]\n",
            "  수집 완료: '\"제 역할이 있다고 생각했어요\" 힙합부터 CEO까지, ...' - 173,184회\n",
            "영상 정보 수집 중... [14/20]\n",
            "  수집 완료: '[ENG SUB] “변치 않고 어디까지 갈 수 있을까”...' - 217,755회\n",
            "\n",
            "수집 완료! 총 10개 영상 정보 수집\n",
            "\n",
            "수집된 영상 목록:\n",
            "  1. 돈 없으면 살 못 뺀다?! 위고비 시대에 맞이할 다이어트의 미래 (w. ... - 198,336회\n",
            "  2. AI가 흉내낼 수도 대체할 수도 없는 단 한 가지 (w. 육식맨, 김범준... - 247,287회\n",
            "  3. 비트코인 지금 사야 할까? 트럼프가 가상자산에 진심인 이유 (w. 빗썸)... - 163,900회\n",
            "  4. [최종화] 이 영상은 성지가 됩니다... 떡상 직전 아티스트 찾는 저점매... - 163,723회\n",
            "  5. 페스티벌에서 관객을 휘어잡는 세 가지 방법 (w. 한로로, 글렌체크, 힙... - 140,483회\n",
            "  6. “이렇게 해도 케이팝인가요?” 바밍타이거가 말하는 얼터너티브 케이팝과 반... - 184,131회\n",
            "  7. 좋아하는 게 직업이 될 수 있을까? 음악으로 먹고사는 1인 음악 미디어의... - 134,228회\n",
            "  8. \"히트곡 공식을 전부 충족한 곡이었어요\" 송소희가 말하는 Not a Dr... - 273,629회\n",
            "  9. \"제 역할이 있다고 생각했어요\" 힙합부터 CEO까지, 자이언티가 계속 변... - 173,184회\n",
            "  10. [ENG SUB] “변치 않고 어디까지 갈 수 있을까” 웨이브투어스 & ... - 217,755회\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2단계에서 배우는 핵심 내용:: 영상 댓글 데이터 수집 (YouTube Data API 활용)\n",
        "---\n",
        "\n",
        "## 2단계 목표:\n",
        "1단계에서 영상의 '성과 지표'(조회수, 좋아요 등 메타데이터)를 확인했다면, 이번 단계에서는 그 성과의 '이유'를 파악하기 위해 시청자들의 구체적인 의견, 즉 **'댓글' 데이터를 수집**합니다. 정량적 데이터를 넘어 정성적 데이터를 확보하여 분석의 깊이를 더하는 핵심적인 과정입니다.\n",
        "\n",
        "## 이번 단계 실습 내용:\n",
        "코드는 1단계에서 수집한 인기 영상 목록을 기반으로, 다음과 같은 체계적인 절차를 통해 댓글 데이터를 수집합니다.\n",
        "\n",
        "1.  **대상 영상 선정:** 1단계에서 생성된 '인기 영상 데이터프레임(`videos_df`)'을 순회하며 댓글을 수집할 영상을 하나씩 지정합니다.\n",
        "2.  **API 데이터 요청:** 각 영상마다, 사전에 등록된 API 키를 사용하여 YouTube Data API에 정식으로 댓글 데이터를 요청합니다.\n",
        "3.  **데이터 선별 기준 적용:** 요청 시 '최신순'이 아닌 **'관련성(relevance)' 순서**로, 사용자가 설정한 개수(`MAX_COMMENTS_PER_VIDEO`)만큼의 댓글을 요청합니다. 이를 통해 좋아요가 많거나 반응이 활발한 주요 댓글을 우선적으로 확보할 수 있습니다.\n",
        "4.  **정보 추출 및 저장:** API로부터 받은 복잡한 원본 데이터에서 **댓글 내용, 작성자, 좋아요 수, 작성 시간** 등 분석에 필요한 핵심 정보만을 추출합니다. 추출된 정보는 분석하기 용이한 형태로 가공되어 `all_comments`라는 리스트에 체계적으로 저장됩니다.\n",
        "\n",
        "---\n",
        "## 코드 속 주요 기능 설명:\n",
        "\n",
        "-   **`youtube.commentThreads().list(...)` (API 요청 함수):**\n",
        "    -   YouTube 서버에 댓글 데이터를 요청하는 핵심 기능입니다.\n",
        "    -   `videoId`: 어떤 영상의 댓글을 수집할지 지정합니다.\n",
        "    -   `maxResults`: 영상 하나당 몇 개의 댓글을 가져올지 수량을 결정합니다.\n",
        "    -   `order='relevance'`: 댓글의 정렬 기준을 지정하여, 단순 시간순이 아닌 중요도 높은 댓글을 먼저 받습니다.\n",
        "\n",
        "-   **`try...except HttpError as e` (안정적인 예외 처리):**\n",
        "    -   데이터 수집 과정에서 발생할 수 있는 다양한 예외 상황에 대처하는 중요한 기능입니다. 이 구문 덕분에 특정 영상에서 오류가 발생해도 전체 프로세스가 중단되지 않습니다.\n",
        "    -   `if 'commentsDisabled'`: 댓글 기능이 비활성화된 영상일 경우, 이를 알리고 다음 영상으로 자동으로 넘어갑니다.\n",
        "    -   `if 'quotaExceeded'`: 할당된 API 일일 사용량을 모두 소진했을 경우, 더 이상의 요청을 멈추고 현재까지 수집된 데이터로 분석을 이어갈 수 있도록 안전하게 작업을 중단합니다.\n",
        "\n",
        "-   **`comments_df.nlargest(3, 'like_count')` (주요 반응 샘플 확인):**\n",
        "    -   수집된 전체 댓글 중에서 **'좋아요' 수를 기준으로 가장 반응이 좋았던 상위 3개의 댓글**을 즉시 출력해주는 기능입니다. 전체 데이터를 상세히 분석하기 전에, 시청자들의 핵심적인 반응을 빠르게 파악할 수 있도록 돕습니다.\n",
        "\n",
        "## 최종 결과물:\n",
        "이 단계가 완료되면, 채널의 주요 영상에 대한 시청자들의 구체적인 의견이 담긴 **'댓글 데이터'**가 `comments_df`라는 이름의 정형화된 데이터프레임(엑셀 표 형식)으로 생성됩니다. 이 데이터는 AI를 활용한 심층 분석 단계의 가장 핵심적인 재료가 됩니다."
      ],
      "metadata": {
        "id": "57B1TNaWpcyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 2단계: 영상 댓글 수집하기 (YouTube Data API 사용)\n",
        "# =================================================================\n",
        "\n",
        "# 수집된 댓글을 저장할 리스트\n",
        "all_comments = []\n",
        "\n",
        "# 수집한 영상이 있을 때만 댓글 수집\n",
        "if not videos_df.empty:\n",
        "    for idx, video in videos_df.iterrows():\n",
        "        video_id = video['video_id']\n",
        "        video_title = video['title']\n",
        "\n",
        "        print(f\"\\n[{idx+1}/{len(videos_df)}] '{video_title[:40]}...' 댓글 수집 중...\")\n",
        "\n",
        "        try:\n",
        "            # YouTube Data API를 사용해서 댓글 가져오기\n",
        "            comments_request = youtube.commentThreads().list(\n",
        "                part='snippet',                    # 기본 정보만 가져오기\n",
        "                videoId=video_id,                  # 영상 ID\n",
        "                maxResults=MAX_COMMENTS_PER_VIDEO, # 가져올 댓글 수\n",
        "                order='relevance'                  # 인기순으로 정렬\n",
        "            )\n",
        "\n",
        "            # API 요청 실행\n",
        "            comments_response = comments_request.execute()\n",
        "\n",
        "            # 이 영상의 댓글들을 저장할 리스트\n",
        "            video_comments = []\n",
        "\n",
        "            # 각 댓글 정보 처리\n",
        "            for item in comments_response['items']:\n",
        "                # 댓글의 기본 정보 추출\n",
        "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "\n",
        "                # 댓글 정보 정리\n",
        "                comment_data = {\n",
        "                    'video_id': video_id,                                      # 영상 ID\n",
        "                    'video_title': video_title,                                # 영상 제목\n",
        "                    'comment_id': item['snippet']['topLevelComment']['id'],    # 댓글 ID\n",
        "                    'text': top_comment['textDisplay'],                        # 댓글 내용\n",
        "                    'author': top_comment['authorDisplayName'],                # 작성자 이름\n",
        "                    'like_count': top_comment.get('likeCount', 0),             # 댓글 좋아요 수\n",
        "                    'published_at': top_comment['publishedAt'],                # 작성 시간\n",
        "                    'reply_count': item['snippet'].get('totalReplyCount', 0),  # 답글 수\n",
        "                    'collected_at': datetime.now().isoformat()                 # 수집 시간\n",
        "                }\n",
        "\n",
        "                video_comments.append(comment_data)\n",
        "\n",
        "            # 이 영상의 댓글들을 전체 댓글 리스트에 추가\n",
        "            all_comments.extend(video_comments)\n",
        "            print(f\"  {len(video_comments)}개 댓글 수집 완료\")\n",
        "\n",
        "            # API 사용량 보호를 위해 0.5초 쉬기\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        except HttpError as e:\n",
        "            error_message = str(e)\n",
        "\n",
        "            if 'commentsDisabled' in error_message:\n",
        "                print(\"  댓글이 비활성화된 영상입니다\")\n",
        "            elif 'quotaExceeded' in error_message:\n",
        "                print(\"  API 사용량 초과! 댓글 수집을 중단합니다\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"  API 오류: {error_message}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  댓글 수집 오류: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"분석할 영상이 없어 댓글 수집을 건너뜁니다\")\n",
        "\n",
        "# 댓글 데이터를 pandas 데이터프레임으로 변환\n",
        "comments_df = pd.DataFrame(all_comments)\n",
        "\n",
        "print(f\"\\n댓글 수집 완료! 총 {len(comments_df)}개 댓글 수집\")\n",
        "\n",
        "# 댓글 수집 결과 출력\n",
        "if not comments_df.empty:\n",
        "    print(f\"고유 작성자: {comments_df['author'].nunique()}명\")\n",
        "    print(f\"평균 좋아요: {comments_df['like_count'].mean():.1f}개\")\n",
        "\n",
        "    print(\"\\n인기 댓글 샘플:\")\n",
        "    # 좋아요가 많은 댓글 3개 출력\n",
        "    top_comments = comments_df.nlargest(3, 'like_count')\n",
        "    for idx, row in top_comments.iterrows():\n",
        "        # 댓글이 길면 앞부분만 출력\n",
        "        text_preview = row['text'][:50] + '...' if len(row['text']) > 50 else row['text']\n",
        "        print(f\"  {row['author']}: {text_preview} (좋아요 {row['like_count']}개)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_-ZIX6AYhfB",
        "outputId": "0b11bda8-39e6-492d-dc62-2cf51b997a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1/10] '돈 없으면 살 못 뺀다?! 위고비 시대에 맞이할 다이어트의 미래 (w. ...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[2/10] 'AI가 흉내낼 수도 대체할 수도 없는 단 한 가지 (w. 육식맨, 김범준...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[3/10] '비트코인 지금 사야 할까? 트럼프가 가상자산에 진심인 이유 (w. 빗썸)...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[4/10] '[최종화] 이 영상은 성지가 됩니다... 떡상 직전 아티스트 찾는 저점매...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[5/10] '페스티벌에서 관객을 휘어잡는 세 가지 방법 (w. 한로로, 글렌체크, 힙...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[6/10] '“이렇게 해도 케이팝인가요?” 바밍타이거가 말하는 얼터너티브 케이팝과 반...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[7/10] '좋아하는 게 직업이 될 수 있을까? 음악으로 먹고사는 1인 음악 미디어의...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[8/10] '\"히트곡 공식을 전부 충족한 곡이었어요\" 송소희가 말하는 Not a Dr...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[9/10] '\"제 역할이 있다고 생각했어요\" 힙합부터 CEO까지, 자이언티가 계속 변...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "[10/10] '[ENG SUB] “변치 않고 어디까지 갈 수 있을까” 웨이브투어스 & ...' 댓글 수집 중...\n",
            "  30개 댓글 수집 완료\n",
            "\n",
            "댓글 수집 완료! 총 300개 댓글 수집\n",
            "고유 작성자: 260명\n",
            "평균 좋아요: 53.2개\n",
            "\n",
            "인기 댓글 샘플:\n",
            "  @user-higirl1004: <a href=\"https://www.youtube.com/watch?v=fi1FmYqXT... (좋아요 619개)\n",
            "  @huggerdungs: 그냥 아티스트 집단이 아니라 대안가족이었네... (좋아요 511개)\n",
            "  @하데쓰: 이제야 말이 좀 통하는 구만 (좋아요 447개)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3단계에서 배우는 핵심 내용:\n",
        "---\n",
        "## 이번 단계에서 배우는 기능들:\n",
        "  - **데이터를 엑셀 파일로 만들기:** 파이썬으로 정리한 데이터 표를 우리가 흔히 사용하는 엑셀(CSV) 파일로 컴퓨터에 저장하는 방법을 배웁니다. `.to_csv()`라는 간단한 명령어로 모든 과정이 끝납니다.\n",
        "  - **실행할 때마다 새 파일로 저장하기:** 코드를 실행할 때마다 결과 파일이 서로 덮어쓰지 않도록, 파일 이름에 현재 날짜와 시간(예: `videos_20250916_224530.csv`)을 붙여주는 방법을 알아봅니다. 이렇게 하면 분석 기록이 차곡차곡 쌓이게 됩니다.\n",
        "  - **어떤 컴퓨터에서든 안전하게 저장하기:** 윈도우, 맥 등 어떤 컴퓨터에서 코드를 실행하든 오류 없이 파일을 잘 저장할 수 있도록, 안전하게 파일 저장 경로를 만드는 방법을 배웁니다. 컴퓨터 환경에 맞게 폴더 경로를 자동으로 완성해주는 똑똑한 기능입니다.\n",
        "  - **한글 깨짐 현상 방지하기:** 엑셀에서 파일을 열었을 때 한글 댓글이나 영상 제목이 깨지지 않고 선명하게 보이도록 만드는 중요한 설정(`encoding='utf-8-sig'`)을 알아봅니다. 컴퓨터에게 한글을 올바르게 인식시키는 '번역 규칙'을 알려주는 것과 같습니다.\n",
        "  - **불필요한 숫자 열 제거하기:** 엑셀 파일을 열었을 때, 데이터와는 상관없는 순서 번호(0, 1, 2...)가 맨 앞에 생기지 않도록 깔끔하게 저장하는 옵션(`index=False`)을 사용합니다.\n",
        "\n",
        "## 내 구글 드라이브에 저장되는 결과물:\n",
        "  - **영상 목록 파일 (videos_... .csv):** 1단계에서 찾은 유튜브 영상들의 목록(제목, 주소 등)이 정리된 엑셀 파일입니다.\n",
        "  - **댓글 데이터 파일 (comments_... .csv):** 2단계에서 수집한 모든 댓글의 자세한 내용(댓글, 작성자, 좋아요 개수 등)이 담겨있는 엑셀 파일입니다.\n",
        "  - 두 파일 모두 우리가 흔히 사용하는 **엑셀이나 구글 시트에서 바로 열어서 내용을 확인**하고, 데이터를 정렬하거나 차트를 만들어 볼 수 있는 아주 편리한 형식입니다."
      ],
      "metadata": {
        "id": "du17MG9rq-L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 3단계: 수집한 데이터 저장하기\n",
        "# =================================================================\n",
        "\n",
        "# 현재 시간을 파일명에 포함 (같은 파일명 중복 방지)\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# 영상 정보 저장 (CSV 파일로)\n",
        "if not videos_df.empty:\n",
        "    video_filename = f\"videos_{timestamp}.csv\"\n",
        "    video_path = os.path.join(SAVE_PATH, video_filename)\n",
        "    # 한글이 깨지지 않도록 utf-8-sig 인코딩 사용\n",
        "    videos_df.to_csv(video_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"영상 데이터 저장: {video_filename}\")\n",
        "\n",
        "# 댓글 정보 저장 (CSV 파일로)\n",
        "if not comments_df.empty:\n",
        "    comments_filename = f\"comments_{timestamp}.csv\"\n",
        "    comments_path = os.path.join(SAVE_PATH, comments_filename)\n",
        "    comments_df.to_csv(comments_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"댓글 데이터 저장: {comments_filename}\")\n",
        "\n",
        "print(f\"저장 완료! 파일 위치: {SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4lduJbb1Y7",
        "outputId": "b6037e16-5e01-477f-feea-14267de95faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "3단계: 데이터 저장 중...\n",
            "==================================================\n",
            "영상 데이터 저장: videos_20250916_204615.csv\n",
            "댓글 데이터 저장: comments_20250916_204615.csv\n",
            "저장 완료! 파일 위치: /content/drive/MyDrive/youtube_analysis/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4단계에서 배우는 핵심 내용:\n",
        "---\n",
        "## 이번 단계에서 배우는 기능들:\n",
        "  - **AI 분석을 위한 데이터 다이어트:** 수많은 댓글 정보(ID, 수집 시간 등) 중에서 앞으로 AI가 분석할 때 꼭 필요한 핵심 정보(누가, 어떤 내용의 댓글을, 어떤 영상에 썼는지 등)만 쏙쏙 골라내는 작업을 합니다. 마치 요리하기 전에 필요한 재료만 꺼내두는 것과 같아요.\n",
        "  - **댓글 양쪽 끝의 불필요한 공백 제거:** 사용자들이 댓글을 쓸 때 실수로 넣은 글자 앞뒤의 빈칸(스페이스)을 `.strip()`이라는 청소 도구를 사용해 자동으로 없애줍니다. 데이터를 깔끔하게 다듬어서 AI가 헷갈리지 않게 만드는 중요한 과정입니다.\n",
        "  - **새로운 데이터 목록 만들기:** 이렇게 골라낸 핵심 정보들만 모아서, AI가 이해하기 쉬운 새로운 목록(`meaningful_comments`)을 만드는 방법을 배웁니다. 마치 중요한 내용만 요약해서 새 노트를 만드는 것과 같습니다.\n",
        "  - **중간 결과 확인하기:** 데이터가 잘 정리되었는지 우리 눈으로 직접 확인할 수 있도록, 처리된 댓글 중 일부를 화면에 예시로 출력하는 방법을 알아봅니다. 요리가 잘 되고 있는지 중간에 맛을 보는 것과 비슷해요.\n",
        "\n",
        "## AI에게 전달될 최종 데이터의 모습:\n",
        "이 단계를 거치면, AI가 분석하기 딱 좋은 형태로 가공된 깔끔한 데이터 목록이 만들어집니다. 각 댓글은 아래 4가지 핵심 정보만 담게 됩니다.\n",
        "\n",
        "- **댓글 내용 (text):** 앞뒤 공백이 깨끗하게 정리된 실제 댓글 내용입니다. AI가 이 텍스트를 읽고 감정이나 주제를 분석하게 됩니다.\n",
        "- **작성자 (author):** 이 댓글을 쓴 사람의 닉네임입니다.\n",
        "- **좋아요 수 (like_count):** 이 댓글이 얼마나 많은 사람들의 공감을 얻었는지 나타내는 중요한 숫자입니다.\n",
        "- **영상 제목 (video_title):** 댓글이 어떤 영상에 달린 것인지 알려주어, 영상의 주제와 댓글 내용을 함께 분석할 수 있도록 돕습니다."
      ],
      "metadata": {
        "id": "D8D51-x9rqci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 4단계: 댓글 데이터 정리 (AI 분석용 준비)\n",
        "# =================================================================\n",
        "\n",
        "\n",
        "# 수집된 댓글들중 필요한 데이터만 선택하여 재가공\n",
        "meaningful_comments = []\n",
        "\n",
        "if not comments_df.empty:\n",
        "    print(f\"전체 댓글: {len(comments_df)}개\")\n",
        "\n",
        "    for _, comment in comments_df.iterrows():\n",
        "\n",
        "        comment_text = comment['text'].strip()\n",
        "\n",
        "        # 댓글 정보 저장\n",
        "        comment_info = {\n",
        "            'text': comment_text,\n",
        "            'author': comment['author'],\n",
        "            'like_count': comment['like_count'],\n",
        "            'video_title': comment['video_title']\n",
        "        }\n",
        "        meaningful_comments.append(comment_info)\n",
        "\n",
        "    # 선별된 댓글 샘플 출력\n",
        "    print(\"\\n주요 댓글 샘플:\")\n",
        "    for i, comment in enumerate(meaningful_comments[:5], 1):\n",
        "        preview_text = comment['text'][:60] + '...' if len(comment['text']) > 60 else comment['text']\n",
        "        print(f\"  {i}. [{comment['like_count']} LIKES] {comment['author']}: {preview_text}\")\n",
        "\n",
        "    if len(meaningful_comments) > 5:\n",
        "        print(f\"  ... (외 {len(meaningful_comments)-5}개)\")\n",
        "\n",
        "else:\n",
        "    print(\"댓글 데이터가 없어 데이터 정리를 건너뜁니다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rof8fAE8ceP_",
        "outputId": "423aa0d2-0db5-4a85-ee88-247d433a844b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 댓글: 300개\n",
            "\n",
            "주요 댓글 샘플:\n",
            "  1. [241 LIKES] @Artmessenger: 이소영입니다! 미술이 과연 머니그라피 채널에서 어떻게 버무려질까? 걱정했는데 접점없는 여러 분야의 분들 통해...\n",
            "  2. [119 LIKES] @나랑-e6x: 재용님 꼭 고정시켜주셔야 합니다!!!! 각기 다른 분야의 전문가를 모시는 것 좋지만 융합과 대화에 열려있는 ...\n",
            "  3. [160 LIKES] @qeraesfda: 다이어트라는 토픽을 얘기하면서 저속노화나 패션 같은 어쩌면 뻔할 수 있는 섭토픽에 미술이 등장하니 신선하고 ...\n",
            "  4. [242 LIKES] @umlanc: 당연히 재용이형 고정인줄.. 고.정.맞.짜.나.\n",
            "  5. [54 LIKES] @Karisma423: 다이어트를 단순히 체중 감량이 아니라 문화, 사회, 산업, 심지어 미술 속 미의 기준까지 폭넓게 연결해서 설...\n",
            "  ... (외 295개)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5단계에서 배우는 핵심 내용:\n",
        "---\n",
        "## 이번 단계에서 배우는 기능들:\n",
        "  - **AI에게 똑똑하게 일 시키기:** 우리가 1~4단계에 걸쳐 수집하고 정리한 영상 및 댓글 데이터를 AI에게 전달하여, 사람처럼 생각하고 분석하는 보고서를 만들게 하는 방법을 배웁니다.\n",
        "  - **AI를 위한 맞춤 보고서 자료 준비:** AI가 영상의 성과와 댓글 반응을 한눈에 파악할 수 있도록, 데이터를 \"제목: OOO, 조회수: OOO회\", \"[좋아요 O개] 작성자: OOO\" 와 같은 보기 좋은 텍스트 형식으로 가공하는 방법을 익힙니다.\n",
        "  - **AI 조종 설명서(프롬프트) 작성법:** AI가 최고의 결과물을 내놓도록, \"당신은 방송 PD를 위한 분석가입니다\"처럼 역할을 부여하고, \"성공 요인은?\", \"시청자 반응은?\", \"다음 콘텐츠 아이디어는?\"처럼 구체적인 질문 목록을 만들어 전달하는 노하우를 배웁니다. 이것이 AI의 성능을 최대로 끌어내는 핵심 기술입니다.\n",
        "  - **AI 분석 결과 파일로 저장하기:** AI가 작성해준 긴 분석 내용을 나중에도 다시 열어볼 수 있도록, 날짜와 시간이 기록된 깔끔한 텍스트 파일(`ai_analysis_... .txt`)로 구글 드라이브에 저장하는 방법을 알아봅니다.\n",
        "\n",
        "## AI가 만들어주는 최종 결과물:\n",
        "이 단계를 실행하면, 단순히 데이터를 요약하는 수준을 넘어, 전문가처럼 깊이 있는 정보를 제공하는 **'AI 분석 리포트'** 파일이 자동으로 생성됩니다. 이 리포트에는 다음과 같은 내용이 담겨 있습니다.\n",
        "\n",
        "- **콘텐츠 성공 비결 분석:** AI가 영상 제목, 길이, 댓글 반응 등을 종합하여 '어떤 영상이 왜 인기가 많은지'에 대한 핵심 요인을 분석해줍니다.\n",
        "- **시청자 마음 심층 분석:** 수많은 댓글을 바탕으로 시청자들이 진짜로 무엇을 좋아하고, 어떤 부분에 아쉬움을 느끼는지, 더 나아가 무엇을 원하는지 등을 꼼꼼하게 짚어줍니다.\n",
        "- **새로운 콘텐츠 아이디어 제안:** 현재 채널의 인기 요소를 기반으로, '다음에 이런 영상을 만들면 성공할 것'이라는 구체적인 기획 아이디어를 3가지 이상 제안해줍니다.\n",
        "- **채널 성장을 위한 현실적인 조언:** 현재 콘텐츠의 잠재적인 문제점이나 개선이 필요한 부분을 지적하고, 채널이 더 성장하기 위한 실용적인 전략을 제시합니다."
      ],
      "metadata": {
        "id": "3wdgdLoNr3UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 5단계: AI 분석 리포트 생성하기\n",
        "# =================================================================\n",
        "\n",
        "GEMINI_MODEL_NAME = 'gemini-2.5-flash'\n",
        "\n",
        "# 영상과 댓글 데이터가 모두 있을 때만 AI 분석 실행\n",
        "if not videos_df.empty and not comments_df.empty:\n",
        "\n",
        "    print(\"AI 분석용 데이터 준비 중...\")\n",
        "\n",
        "    # 영상 정보를 텍스트로 정리\n",
        "    video_summary = []\n",
        "    for _, video in videos_df.iterrows():\n",
        "        summary = f\"\"\"제목: {video['title']}\n",
        "조회수: {video['view_count']:,}회\n",
        "좋아요: {video['like_count']:,}개\n",
        "댓글: {video['comment_count']:,}개\n",
        "업로드: {video['upload_date']}\n",
        "재생시간: {video['duration_string']}\"\"\"\n",
        "        video_summary.append(summary)\n",
        "\n",
        "    videos_text = '\\n\\n'.join(video_summary)\n",
        "\n",
        "    # 선별된 댓글들을 AI 분석용으로 정리\n",
        "    comments_for_ai = []\n",
        "    if meaningful_comments:\n",
        "        for comment in meaningful_comments:\n",
        "            # 댓글을 읽기 쉽게 정리\n",
        "            comment_line = f\"[{comment['like_count']} LIKES ] {comment['author']}: {comment['text']}\"\n",
        "            comments_for_ai.append(comment_line)\n",
        "\n",
        "    try:\n",
        "        print(\"AI 분석 요청 중...\")\n",
        "\n",
        "        # AI에게 분석을 요청할 텍스트 작성 (실제 댓글 내용 포함)\n",
        "        analysis_prompt = f\"\"\"YouTube 채널 '{CHANNEL_NAME}' 분석 데이터입니다.\n",
        "방송 PD와 콘텐츠 기획자를 위한 실용적인 분석을 해주세요.\n",
        "\n",
        "=== 분석 대상 ===\n",
        "채널: {CHANNEL_NAME}\n",
        "조건: 최근 인기 영상 중 {VIEW_THRESHOLD:,}회 이상\n",
        "\n",
        "=== 인기 영상 성과 ===\n",
        "{videos_text}\n",
        "\n",
        "=== 시청자 댓글 반응 (댓글 좋아요 순) ===\n",
        "{comments_for_ai}\n",
        "\n",
        "=== 분석 요청사항 ===\n",
        "다음 관점에서 분석해주세요:\n",
        "\n",
        "1. 현재 인기 영상의 성공 요인\n",
        "   - 제목 패턴과 특징\n",
        "   - 영상 길이와 성과의 관계\n",
        "   - 시청자들이 좋아하는 콘텐츠 스타일\n",
        "\n",
        "2. 댓글을 통한 시청자 반응 분석\n",
        "   - 전반적인 시청자 만족도\n",
        "   - 댓글에서 나타나는 주요 관심사와 반응\n",
        "   - 긍정적/부정적 의견의 주요 내용\n",
        "   - 시청자들이 원하는 콘텐츠 요소\n",
        "\n",
        "3. 실행 가능한 콘텐츠 전략 제안\n",
        "   - 다음 콘텐츠 기획 아이디어 3가지\n",
        "   - 시청자 참여도 높이는 구체적 방법\n",
        "   - 댓글 반응을 개선하기 위한 제안\n",
        "\n",
        "4. 주의사항\n",
        "   - 현재 콘텐츠의 잠재적 문제점\n",
        "   - 개선이 필요한 부분\n",
        "\n",
        "방송 현업에서 바로 쓸 수 있는 구체적이고 실용적인 조언을 한국어로 해주세요.\n",
        "댓글 내용을 근거로 구체적인 예시를 들어 설명해주세요.\"\"\"\n",
        "\n",
        "        # Gemini AI에게 분석 요청\n",
        "        response = genai_client.models.generate_content(\n",
        "            model=GEMINI_MODEL_NAME,\n",
        "            contents=analysis_prompt\n",
        "        )\n",
        "\n",
        "        ai_analysis = response.text\n",
        "\n",
        "        print(\"AI 분석 완료!\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"AI 분석 결과\")\n",
        "        print(\"=\"*60)\n",
        "        print(ai_analysis)\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # AI 분석 결과를 파일로 저장\n",
        "        analysis_filename = f\"ai_analysis_{timestamp}.txt\"\n",
        "        analysis_path = os.path.join(SAVE_PATH, analysis_filename)\n",
        "\n",
        "        with open(analysis_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"=== {CHANNEL_NAME} AI 분석 리포트 ===\\n\")\n",
        "            f.write(f\"분석 일시: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"분석 영상: {len(videos_df)}개\\n\")\n",
        "            f.write(f\"분석 댓글: {len(comments_df)}개\\n\")\n",
        "            f.write(f\"AI 전달 댓글: {len(meaningful_comments)}개\\n\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\")\n",
        "            f.write(ai_analysis)\n",
        "\n",
        "        print(f\"\\nAI 분석 결과 저장: {analysis_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"AI 분석 오류: {e}\")\n",
        "        print(\"API 키를 확인하거나 나중에 다시 시도해주세요\")\n",
        "\n",
        "else:\n",
        "    if videos_df.empty:\n",
        "        print(\"분석할 영상 데이터가 없습니다\")\n",
        "    elif comments_df.empty:\n",
        "        print(\"분석할 댓글 데이터가 없습니다\")\n",
        "    else:\n",
        "        print(\"AI 연결이 안되어 분석을 건너뜁니다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_eM0yMMYmcw",
        "outputId": "0d68aa27-0bf1-4dcd-cbbf-698a16b23115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI 분석용 데이터 준비 중...\n",
            "AI 분석 요청 중...\n",
            "AI 분석 완료!\n",
            "\n",
            "============================================================\n",
            "AI 분석 결과\n",
            "============================================================\n",
            "## YouTube 채널 '@Moneygraphy' 분석 보고서: 방송 PD 및 콘텐츠 기획자를 위한 실용적 제안\n",
            "\n",
            "'@Moneygraphy' 채널은 '경제'라는 다소 딱딱할 수 있는 주제를 인문학적 통찰과 다양한 분야의 접목을 통해 깊이 있고 흥미롭게 다루며, 충성도 높은 시청자층을 확보하고 있습니다. 특히, 긴 호흡의 롱폼 콘텐츠로 높은 조회수와 참여도를 기록하고 있는 점은 현재 유튜브 트렌드 속에서 차별화된 강점으로 평가됩니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 1. 현재 인기 영상의 성공 요인\n",
            "\n",
            "#### 가. 제목 패턴과 특징\n",
            "'@Moneygraphy' 채널의 인기 영상 제목들은 다음과 같은 특징을 보이며 시청자들의 클릭을 유도하고 있습니다.\n",
            "\n",
            "*   **호기심 유발형 질문 또는 도발적 문구:** \"돈 없으면 살 못 뺀다?!\", \"AI가 흉내낼 수도 대체할 수도 없는 단 한 가지\", \"비트코인 지금 사야 할까?\" 등 시청자들이 일상에서 한 번쯤 고민해볼 만한 질문을 던져 즉각적인 관심을 불러일으킵니다.\n",
            "*   **시의성 있는 핵심 키워드 포함:** \"위고비\", \"AI\", \"비트코인\", \"트럼프\" 등 최신 트렌드나 사회적 이슈가 되는 키워드를 명확히 제시하여 정보 탐색 목적의 시청자를 유입합니다.\n",
            "*   **전문성 및 게스트 활용 강조:** \"(w. 정희원, 장석종, 이재용, 이소영)\", \"(w. 육식맨, 김범준, 이재용, 김세엽)\" 등 저명하거나 화제성 있는 게스트의 이름을 명시하여 콘텐츠의 신뢰도와 깊이를 간접적으로 드러냅니다. 이는 '전문가의 통찰'을 기대하는 시청자들에게 매력적으로 작용합니다.\n",
            "*   **시리즈 브랜드명 명시:** \"토킹 헤즈\", \"B주류경제학\", \"머니 코드\" 등 자체 시리즈 브랜드를 제목에 넣어 충성 시청자들이 쉽게 콘텐츠를 인지하고 접근하도록 돕습니다.\n",
            "*   **흥미로운 서사 또는 비전 제시:** \"이 영상은 성지가 됩니다... 떡상 직전 아티스트 찾는 저점매수 월드컵\", \"얼터너티브 케이팝과 반골 기질 (feat. RM)\", \"힙합부터 CEO까지, 자이언티가 계속 변화한 이유\"와 같이 콘텐츠가 다룰 인물의 특별한 서사나 미래 지향적인 통찰을 예고하여 기대를 높입니다.\n",
            "\n",
            "#### 나. 영상 길이와 성과의 관계\n",
            "제공된 데이터에 따르면, 채널의 인기 영상들은 대부분 30분에서 1시간이 넘는 **롱폼 콘텐츠**임에도 불구하고 높은 조회수를 기록하고 있습니다. 이는 다음과 같은 의미를 가집니다.\n",
            "\n",
            "*   **롱폼 선호 시청자층 확보:** 시청자들은 단순히 짧고 자극적인 정보를 넘어, 한 주제에 대해 심도 깊은 논의를 나누는 긴 영상을 적극적으로 소비하고 있습니다. 댓글에서도 \"[292 LIKES ] @kdh-rv3hs: 이 프로그램의 인사이트... 너무 재밌습니다.. 보다가 자야지 라고 생각하고 잇는데 벌써 30분이 지나버렸네요..\"나 \"[17 LIKES ] @이승환-j5i: 제발 러닝타임 50분 밑으로 내려가면 안됩니다ㅜㅎㅎ\"와 같이 롱폼 콘텐츠 자체에 대한 긍정적인 평가가 많습니다.\n",
            "*   **깊이 있는 대화의 가치:** 긴 재생시간은 복잡한 주제를 다양한 각도에서 심층적으로 탐구할 수 있는 기반이 됩니다. 이는 시청자들이 채널에 기대하는 '인사이트'와 '지적 만족감'을 충족시키는 핵심 요소입니다. \"AI가 인간처럼 추상적인 정보를 만들어내고 그걸 믿을 수 있느냐.. 인간들이 변화한 환경에서 새로운 추상 정보, 새로운 가치관을 만들어 낼 때가 왔다라는 이야기..!\"와 같은 심도 있는 논의가 가능했던 것도 롱폼 덕분입니다.\n",
            "*   **몰입도 높은 콘텐츠 증명:** 시청자들이 긴 시간을 기꺼이 투자한다는 것은 콘텐츠의 구성, 진행, 게스트의 발언 등이 매우 몰입도가 높다는 것을 방증합니다.\n",
            "\n",
            "#### 다. 시청자들이 좋아하는 콘텐츠 스타일\n",
            "시청자들의 댓글 반응을 종합해보면, 다음과 같은 스타일의 콘텐츠를 특히 선호하는 것으로 보입니다.\n",
            "\n",
            "*   **다학제적 접근을 통한 통찰 (특히 '토킹 헤즈'):** \"한 주제로 다양한 분야 업계 분들이 각자 생각 나누는 거 너무 좋습니다\", \"다이어트라는 토픽을 얘기하면서 ... 미술이 등장하니 신선하고 재밌음. 과거/현재/미래의 미의 기준을 다른 시각으로 생각해 볼 수 있어서 좋았음\"과 같이, 한 가지 주제를 여러 분야의 전문가들이 각자의 시각으로 풀어내는 방식에 열광합니다. '접점 없어 보이는' 분야들의 연결에서 오는 신선함과 깊이를 높이 평가합니다.\n",
            "*   **아티스트의 철학과 진솔한 이야기 ('머니 코드'):** \"사람 자체가 멋있음.... 자신만의 기준이 명확하게 서있는 것 같아서 본인이 하는 음악들이 괜히 나온게 아니구나 싶음\", \"얼마나 많이 고민했고 단단하게 자신을 빌드업했는지 느껴짐\" 등 음악 그 자체를 넘어 아티스트의 삶의 태도, 철학, 작업 과정에서의 고뇌를 깊이 있게 다루는 인터뷰에 감동하고 공감합니다. 특히 국악과 크로스오버를 다룬 송소희 편은 \"송소희가 특별한 건 본인의 색을 추구했다는 거...결국 결실을 이뤄냈다는 것이 대단함\"과 같은 반응을 이끌어냈습니다.\n",
            "*   **전문가의 날카로운 분석과 논리적인 대화 ('B주류경제학'):** 이재용 회계사, 타일러 등 전문가들의 명확하고 논리적인 분석과 유연한 사고방식에 높은 만족도를 보입니다. \"이재용 회계사님의 독보적인 분석\", \"타일러 님 생각이 굉장히 논리적이고 유연해서 좋아요\" 등의 댓글에서 알 수 있듯, 깊이 있는 지식 전달에 대한 니즈가 큽니다.\n",
            "*   **진정성 있는 진행과 뛰어난 섭외력:** 강지영 아나운서의 안정적이고 깊이 있는 진행, 룩키팝과 룩삼 등의 호스트가 보여주는 음악에 대한 진심(\"우키팝님이 엄청나게 밀도있는 질문만 하시니까 아티스트들도 진짜 겉치레로 하는 말이 아니라 몰입해서 한층 더 딥하게 답변해준다는게 미치게 좋네요\")과 채널의 섭외력에 대한 칭찬이 많습니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. 댓글을 통한 시청자 반응 분석\n",
            "\n",
            "#### 가. 전반적인 시청자 만족도\n",
            "시청자 만족도는 **매우 높습니다.** 댓글 전반에서 \"최고\", \"너무 좋습니다\", \"기다렸다\", \"유익했다\", \"인사이트가 깊었다\", \"감동적이다\", \"애정합니다\", \"평생 컨텐츠\"와 같은 극찬이 이어집니다. 특히 \"이제야 말이 좀 통하는 구만\" (447 LIKES)이라는 댓글은 이 채널이 기존 유튜브에서 찾기 어려웠던 '지적 갈증'을 해소해주고 있음을 시사합니다.\n",
            "\n",
            "#### 나. 댓글에서 나타나는 주요 관심사와 반응\n",
            "\n",
            "*   **게스트에 대한 높은 관심과 애정:**\n",
            "    *   **고정 출연 요청:** 이재용 회계사에 대한 \"재용님 꼭 고정시켜주셔야 합니다!!!!\", \"돌아왔구나 재용신..\" 등의 반응은 특정 게스트에 대한 높은 로열티를 보여줍니다.\n",
            "    *   **새로운 시너지에 대한 호평:** \"이소영입니다! 미술이 과연 머니그라피 채널에서 어떻게 버무려질까? 걱정했는데 접점없는 여러 분야의 분들 통해서 깊은 인사이트를 얻을 수 있었다\"처럼 게스트가 직접 자신의 출연에 대한 만족감을 표하거나, 육식맨에 대한 \"육식맨님 역할이 되게 크네요\", \"육식맨은 맨날 여기저기 유투브 댓글로만 봤는데 통찰 있는 사람같네 말도 재밌고\"와 같이 게스트의 역할과 통찰력에 대한 긍정적인 평가가 많습니다.\n",
            "*   **콘텐츠의 깊이와 인사이트에 대한 갈망:**\n",
            "    *   \"한 주제로 다양한 분야 업계 분들이 각자 생각 나누는 거 너무 좋습니다\" (34 LIKES)\n",
            "    *   \"다이어트를 단순히 체중 감량이 아니라 문화, 사회, 산업, 심지어 미술 속 미의 기준까지 폭넓게 연결해서 설명해주신 게 너무 인상 깊었어요.\" (54 LIKES)\n",
            "    *   \"위고비가 역설적으로 마름에 대한 집착을 해방시켜줄 거란 통찰이 너무 좋음\" (75 LIKES)\n",
            "    *   \"AI가 인간처럼 추상적인 정보를 만들어내고 그걸 믿을 수 있느냐.. 인간들이 변화한 환경에서 새로운 추상 정보, 새로운 가치관을 만들어 낼 때가 왔다라는 이야기..!\" (56 LIKES)\n",
            "    *   이처럼 시청자들은 피상적인 정보를 넘어, 삶과 사회를 깊이 있게 이해하고 새로운 관점을 제시하는 콘텐츠에 적극적으로 반응합니다.\n",
            "*   **롱폼 콘텐츠 포맷 자체에 대한 지지:**\n",
            "    *   \"제발 러닝타임 50분 밑으로 내려가면 안됩니다ㅜㅎㅎ\" (17 LIKES)\n",
            "    *   \"분량 한시간인거 보고 바로 개추 박음\" (22 LIKES)\n",
            "    *   \"1시간이 후딱 지나갔어요, 다양한 관점에서 나누는 대화 너무 즐겁고 인사이트가 깊었습니다.\" (11 LIKES)\n",
            "    *   \"이렇게 긴 호흡으로 제작된 영상들이 많이 없기도 하고, 있더라도 밀도가 높지 않은 경우가 많은데...흐르는 수많은 영상들의 강물에 거슬러 오르는 연어같아요\" (3 LIKES)\n",
            "    *   시청자들은 긴 재생시간이 콘텐츠의 질을 담보한다고 인식하며, 오히려 롱폼을 채널의 고유한 매력으로 받아들이고 있습니다.\n",
            "*   **음악 콘텐츠의 감동과 공감:**\n",
            "    *   \"바밍타이거 보니까 왜 눈물 나려고 하지 나도 늘 저런 끈끈한 가족 같은 집단에 속하길 원했던 것 같음...\" (316 LIKES)\n",
            "    *   \"송소희님의 '존버가 승리한다.'라는 말이 가볍게 느껴지지 않네요. 국악에 대해, 본인의 새로운 음악에 대해 정말 많은 고민을 해왔다는 것이 느껴졌습니다.\" (439 LIKES)\n",
            "    *   \"머니코드 보면서 느끼는게 단순히 음악이 좋은 사람이 아니라, 자신의 음악에 대한 생각이 깊은 아티스트들을 데려와서 많은 이야기를 들려주는게 너무 좋은거 같아요.\" (26 LIKES)\n",
            "    *   음악 콘텐츠에서는 아티스트의 진솔한 내면과 음악에 대한 철학, 팀워크에서 오는 감동에 깊이 공감하는 반응이 많습니다.\n",
            "*   **높은 제작 퀄리티에 대한 칭찬:** \"제작진들 신경을 엄청 많이 쓰신게 보이네요\", \"와중에 마이크 수음을 어떻게 하신건지 너무 궁금하네요\" (30 LIKES)처럼 제작진의 노력과 기술적인 완성도에 대한 칭찬도 눈에 띕니다.\n",
            "\n",
            "#### 다. 긍정적/부정적 의견의 주요 내용\n",
            "*   **긍정적 의견 (대부분):** 위에서 언급한 대로 콘텐츠의 깊이, 게스트의 전문성, 진행의 탁월함, 롱폼 형식, 그리고 음악 콘텐츠의 진정성에 대한 극찬이 주를 이룹니다. 시청자들은 채널을 통해 지적 성장과 정서적 만족을 동시에 얻고 있다고 평가합니다.\n",
            "*   **부정적 의견 (거의 없음):** 콘텐츠의 질 자체에 대한 직접적인 부정적 의견은 거의 찾아볼 수 없습니다. 다만, 일부 아쉬움이나 개선 요청은 다음과 같습니다.\n",
            "    *   **시리즈 종료에 대한 아쉬움:** '머니 코드' 최종화 영상에서 \"시즌3 해라 진짜\", \"끝내지 마요 룩키팝 영원리 머니코드 해줘\" (46 LIKES) 등 시리즈의 계속적인 제작을 원하는 목소리가 높았습니다. 이는 채널에 대한 높은 충성도와 애정의 반증입니다.\n",
            "    *   **스폰서십 통합에 대한 의문:** \"이 영상에서 전체적으로 이야기하고자 하는 내용들은 빗썸이 아닌데 왜 끝자락 잠깐 나오는 광고에 꽂힌거지 댓글알바인가(?)\" (5 LIKES)와 같이 스폰서십 내용이 메인 콘텐츠와 다소 이질적으로 느껴질 경우, 일부 시청자들은 의문을 제기할 수 있습니다. 광고의 자연스러운 연결에 대한 고민이 필요합니다.\n",
            "\n",
            "#### 라. 시청자들이 원하는 콘텐츠 요소\n",
            "*   **다양한 분야 전문가 조합 토크쇼 (토킹 헤즈 지속):** \"한 주제로 다양한 분야 업계 분들이 각자 생각 나누는 거 너무 좋습니다\"를 통해 알 수 있듯이, '토킹 헤즈'의 포맷을 유지하며 새로운 주제와 조합으로 깊이 있는 대화를 이어가기를 원합니다.\n",
            "*   **인사이트 있는 게스트 재초대:** 이재용 회계사, 육식맨, 이소영 작가, 김윤하 등 이미 검증된 게스트들의 재출연을 적극적으로 요청합니다.\n",
            "*   **아티스트의 철학을 담은 심층 인터뷰 (머니 코드 지속):** 음악을 넘어 아티스트의 삶과 가치관을 조명하는 '머니 코드' 시리즈의 지속적인 제작과 더불어, \"머니 코드 덕분에 기존 취향으로는 들어보지도 않았을 다양한 음악 아티스트를 알게 되면서 나도 이런 거에 끌리는 사람이었구나를 알게 되었네요.\"처럼 새로운 아티스트의 발굴 및 소개를 원합니다.\n",
            "*   **롱폼 유지:** \"러닝타임 50분 밑으로 내려가면 안됩니다\"처럼 콘텐츠의 길이를 줄이지 않고 깊이를 유지하기를 원합니다.\n",
            "*   **시청자 참여 기회:** 영상에서 다뤄진 음악의 플레이리스트 요청(\"머니코드 하실때 아티스트편도 그렇고 방송에 나온 노래들 플레이리스트 따로 만들어두시면 안될까요?\"), 특정 질문에 대한 댓글 공유 유도 등 간접적인 참여 기회를 통해 소통하고 싶어 합니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. 실행 가능한 콘텐츠 전략 제안\n",
            "\n",
            "#### 가. 다음 콘텐츠 기획 아이디어 3가지\n",
            "\n",
            "1.  **아이디어 1: '토킹 헤즈' 확장 - '미래 사회의 가치관 재정립' 시리즈**\n",
            "    *   **내용:** AI, 위고비, 비트코인 등 기술 및 사회 변화가 가속화되는 시대에 인간의 가치, 윤리, 삶의 방식이 어떻게 재정립되어야 하는지에 대한 심층 대담.\n",
            "    *   **게스트 조합 (예시):**\n",
            "        *   **주제:** \"AI 시대, 인간의 노동과 행복은 어디에 있는가?\"\n",
            "        *   **전문가:** AI 개발자, 사회학자, 철학자, 직업 컨설턴트 (or 경제학자)\n",
            "    *   **특징:** 'AI가 흉내낼 수도 대체할 수도 없는 단 한 가지' 편에서 시청자들이 \"내가 '생각'을 스스로 하고 있지 않다고 종종 느껴요\" 등의 깊이 있는 고민을 나눈 것에 착안. '다이어트의 미래' 편에서 미술과 연결한 것처럼, '기술 변화'라는 주제에 '인문학/철학'적 관점을 접목하여 시청자들이 스스로의 삶을 성찰할 기회를 제공합니다. 기존 채널의 강점인 '다학제적 접근'을 극대화할 수 있습니다.\n",
            "    *   **기대 효과:** 시청자들이 가장 갈망하는 '인사이트'를 가장 직접적으로 제공하며, 채널의 지적 권위를 더욱 확고히 할 수 있습니다.\n",
            "\n",
            "2.  **아이디어 2: '머니 코드' 스핀오프 - '힙스터 경제학: 취향이 돈이 되는 시장'**\n",
            "    *   **내용:** 음악뿐 아니라 미술, 패션, 음식, 공간 등 특정 취향을 기반으로 한 서브컬처 시장이 어떻게 형성되고, 소비되며, 경제적 가치를 창출하는지 분석하는 시리즈.\n",
            "    *   **게스트 조합 (예시):**\n",
            "        *   **주제:** \"인디 음악 시장의 생존 전략: 팬덤과 플랫폼 사이에서\"\n",
            "        *   **전문가:** 인디 레이블 대표, 음악 평론가 (김윤하 재초대), 팬덤 경제 전문 마케터, 음악 페스티벌 기획자.\n",
            "    *   **특징:** '머니 코드' 시청자들이 음악을 통해 아티스트의 철학뿐 아니라 '덕질'과 '취향 공동체'에 대한 높은 관심(\"바밍타이거 보니까 왜 눈물 나려고 하지...끈끈한 가족 같은 집단에 속하길 원했던 것 같음\")을 보인 점을 확장. '좋아하는 게 직업이 될 수 있을까?' 편처럼, 취향이 경제활동으로 이어지는 현상을 심층적으로 다루며 'Moneygraphy'의 브랜드 아이덴티티와도 자연스럽게 연결합니다.\n",
            "    *   **기대 효과:** '머니 코드'의 충성 시청자들을 만족시키면서도, '머니'라는 키워드와의 연관성을 강화하여 채널 전체의 일관성을 높일 수 있습니다. '비주류 경제학'의 관점에서 '취향 시장'을 분석하는 재미를 줄 수 있습니다.\n",
            "\n",
            "3.  **아이디어 3: 'B주류경제학' 확장 - '지정학적 리스크와 투자 전략'**\n",
            "    *   **내용:** 글로벌 지정학적 이슈 (선거, 분쟁, 무역 갈등 등)가 국내외 자산 시장과 개인의 투자 포트폴리오에 미치는 영향에 대해 전문가들과 논의.\n",
            "    *   **게스트 조합 (예시):**\n",
            "        *   **주제:** \"미국 대선이 바꿀 글로벌 경제 지도: 한국 투자자의 대응 전략\"\n",
            "        *   **전문가:** 국제 정치 전문가, 금융 투자 전문가, 이재용 회계사 (재초대), 해외 경제 전문 기자 (타일러 재초대).\n",
            "    *   **특징:** '비트코인' 편에서 트럼프와 가상자산의 관계를 다루며 \"큰 흐름이 어디로 가고있는지는 알수있음 다만 이러다가도 어떤위기가 갑자기 올지모름\"과 같은 시청자들의 불안감과 '대비하는 투자'에 대한 니즈를 파악. 단순히 투자 상품을 추천하는 것을 넘어, 거시적인 관점에서 리스크 관리와 장기적인 투자 전략을 제시합니다.\n",
            "    *   **기대 효과:** 'Moneygraphy'의 본래 정체성에 부합하는 전문성을 강화하며, 시청자들이 실질적인 인사이트를 얻을 수 있도록 돕습니다. '이재용 회계사' 재초대로 기존 팬들의 만족도를 높일 수 있습니다.\n",
            "\n",
            "#### 나. 시청자 참여도 높이는 구체적 방법\n",
            "\n",
            "1.  **사전 질문 공모 및 영상 내 반영:**\n",
            "    *   **방법:** 영상 기획 단계에서 인스타그램 스토리, 유튜브 커뮤니티 탭 등을 통해 특정 주제나 게스트에게 던질 질문을 시청자들에게 공모합니다. 선정된 질문은 실제 영상에서 게스트에게 질문하고, 질문자 ID를 화면에 노출하여 참여감을 높입니다.\n",
            "    *   **댓글 근거:** \"중간에 들어가서 보고싶다고 느낄정도로 참여 욕구가 샘솟게 하는 대화의 장이라 너무 좋았습니다\" (26 LIKES)에서 시청자들이 대화에 '참여하고 싶어 하는' 욕구를 읽을 수 있습니다.\n",
            "\n",
            "2.  **'최애 인사이트' 댓글 이벤트 및 큐레이션:**\n",
            "    *   **방법:** 영상 업로드 후, 가장 기억에 남는 문구나 인사이트를 댓글로 공유하도록 유도하고, 매주 또는 매달 '최애 인사이트'를 선정하여 다음 영상의 짧은 오프닝으로 사용하거나 커뮤니티 탭에 게시합니다. (머니그라피의 댓글 좋아요 순 정렬 기능 활용)\n",
            "    *   **댓글 근거:** \"비교의식을 다이어트하자. 제 기준 올해 최고의 인사이트가 있는 말이네요.\" (75 LIKES)와 같이 시청자들은 영상 내 핵심 메시지에 높은 가치를 부여하고 있습니다. 이를 공식적으로 인정하고 공유함으로써 시청자들의 적극적인 감상 공유를 독려할 수 있습니다.\n",
            "\n",
            "3.  **'머니 코드' 플레이리스트 및 아티스트 후속 콘텐츠:**\n",
            "    *   **방법:** '머니 코드' 영상에서 소개된 음악이나 아티스트들의 추천 곡을 유튜브 플레이리스트로 제작하여 제공하고, 시청자들이 댓글로 자신의 '인생곡'이나 '처음 설렘을 느꼈던 음악'을 공유하도록 유도합니다. (현재 '머니 코드' 영상에 댓글 이벤트로 진행 중인 부분을 더욱 확장) 또한, 반응이 좋았던 아티스트에 대한 짧은 후속 인터뷰 영상 (ex. 쇼츠)을 제작하여 궁금증을 해소해줍니다.\n",
            "    *   **댓글 근거:** \"진짜 머니코드 하실때 아티스트편도 그렇고 방송에 나온 노래들 플레이리스트 따로 만들어두시면 안될까요? 오늘 나온 32곡 모두 들어보고 싶네요!\" (45 LIKES)처럼 음악 관련 콘텐츠에서 시청자들은 적극적으로 음악 정보를 원하고 있습니다.\n",
            "\n",
            "#### 다. 댓글 반응을 개선하기 위한 제안\n",
            "\n",
            "1.  **제작진의 적극적인 댓글 소통 확대:**\n",
            "    *   **방법:** 현재 채널에서 이벤트 공지 댓글만 주로 보이고 있는데, 시청자들이 남긴 심도 있는 질문이나 통찰력 있는 댓글에 제작진이 직접 대댓글을 달아 소통하는 횟수를 늘립니다. 특히 게스트 섭외에 대한 긍정적인 댓글 (\"섭외담당자분 칭찬 드립니당 ㅎㅎ\")이나 제작 퀄리티에 대한 칭찬 (\"마이크 수음을 어떻게 하신건지\")에는 감사의 메시지를 전달하여 더욱 친밀한 관계를 형성합니다.\n",
            "    *   **댓글 근거:** \"@Moneygraphy\" 계정의 이벤트 댓글이 346 LIKES, 88 LIKES 등 높은 좋아요를 받는 것을 보면, 시청자들은 채널과의 상호작용에 긍정적으로 반응할 준비가 되어 있습니다.\n",
            "\n",
            "2.  **스폰서십 콘텐츠의 자연스러운 통합 및 명확한 가치 제시:**\n",
            "    *   **방법:** 'B주류경제학'의 빗썸 스폰서십처럼, 광고성 댓글에 대한 의문이 제기된 경우를 참고하여 스폰서십 콘텐츠는 기획 단계부터 메인 주제와 유기적으로 연결되도록 노력합니다. 예를 들어, 스폰서 기업의 비전이나 가치가 채널의 핵심 메시지('인사이트', '미래 예측')와 어떻게 부합하는지 명확히 설명하는 섹션을 영상 내에 포함하여 단순히 광고를 넘어선 '정보' 또는 '가치'를 제공합니다.\n",
            "    *   **댓글 근거:** \"이 영상에서 전체적으로 이야기하고자 하는 내용들은 빗썸이 아닌데 왜 끝자락 잠깐 나오는 광고에 꽂힌거지 댓글알바인가(?)\" (5 LIKES) 이 댓글은 광고성 내용이 본질적인 콘텐츠 흐름과 분리될 때 시청자들이 부정적으로 인식할 수 있음을 보여줍니다.\n",
            "\n",
            "3.  **영상 시작 전 '이전 편 반응 하이라이트' 도입:**\n",
            "    *   **방법:** 새로운 영상 시작 전, 지난 에피소드에서 시청자들이 남긴 가장 뜨거웠던 댓글이나 핵심 인사이트를 15~30초 내외의 짧은 영상으로 소개합니다.\n",
            "    *   **댓글 근거:** 시청자들이 이전 영상에 대한 '내적 친밀감'을 표하고, \"이전편 다 보고 나니까 바로 올라와 있네 ㅋㅋ 진짜 접점이 없지만 내적 친밀감은 높은 조합 계속 가는 거 넘 좋다.\" (31 LIKES)와 같이 콘텐츠 간의 연결성을 중요하게 생각합니다. 이를 통해 신규 시청자들에게는 채널의 분위기를 알리고, 기존 시청자들에게는 커뮤니티의 일원이라는 소속감을 강화할 수 있습니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. 주의사항 및 개선이 필요한 부분\n",
            "\n",
            "#### 가. 현재 콘텐츠의 잠재적 문제점\n",
            "\n",
            "1.  **채널 브랜드 정체성의 모호성 (초기 진입자 대상):**\n",
            "    *   'Moneygraphy'라는 채널명은 '돈', '경제'와 직결되지만, 인기 콘텐츠 중 '머니 코드' 시리즈는 순수 예술(음악)에 대한 깊이 있는 이야기를 주로 다룹니다. 물론 '머니'를 '가치'로 확장하여 해석할 수 있지만, 채널에 처음 유입되는 시청자들은 채널명과 콘텐츠 주제 간의 괴리감으로 인해 혼란을 느낄 수 있습니다.\n",
            "    *   **댓글 근거:** \"[241 LIKES ] @Artmessenger: 이소영입니다! 미술이 과연 머니그라피 채널에서 어떻게 버무려질까? 걱정했는데 접점없는 여러 분야의 분들 통해서 깊은 인사이트를 얻을 수 있었던 즐거운 수다였습니다.\" 이소영 작가의 댓글처럼, 게스트조차 '머니그라피에서 미술'이라는 조합에 처음에는 의문을 가졌음을 알 수 있습니다.\n",
            "2.  **특정 게스트 의존도 (특히 'B주류경제학', '토킹 헤즈'):**\n",
            "    *   이재용 회계사, 육식맨 등 특정 게스트의 전문성과 매력이 채널의 큰 성공 요인으로 작용하고 있습니다. 이는 긍정적이지만, 해당 게스트들의 출연이 어려워질 경우 콘텐츠 제작의 연속성이나 화제성에 영향을 미칠 수 있습니다.\n",
            "    *   **댓글 근거:** \"재용님 꼭 고정시켜주셔야 합니다!!!!\" (119 LIKES), \"돌아왔구나 재용신..\" (86 LIKES)처럼 시청자들이 특정 게스트에 대한 의존도와 기대가 높음을 보여줍니다.\n",
            "3.  **롱폼 콘텐츠의 잠재적 진입 장벽:**\n",
            "    *   현재는 롱폼이 성공 요인이지만, 유튜브 전체 트렌드는 여전히 짧고 즉각적인 콘텐츠를 선호하는 경향이 있습니다. 새로운 시청자를 유입하기 위해서는 롱폼 콘텐츠의 깊이를 유지하면서도, 진입 장벽을 낮출 수 있는 추가적인 전략이 필요할 수 있습니다.\n",
            "\n",
            "#### 나. 개선이 필요한 부분\n",
            "\n",
            "1.  **채널 브랜드 스토리 강화 및 통일성 부여:**\n",
            "    *   **개선 방안:** 'Moneygraphy'가 추구하는 '돈' 또는 '가치'의 의미를 채널 소개나 각 시리즈의 오프닝 등을 통해 명확하게 전달해야 합니다. 예를 들어, \"단순한 돈을 넘어, 우리 삶의 가치와 미래를 탐구하는 채널\"과 같은 슬로건을 활용하여 '머니 코드'의 음악 콘텐츠나 '토킹 헤즈'의 문화/사회 콘텐츠가 채널의 비전과 어떻게 연결되는지 설명하는 내러티브를 강화합니다.\n",
            "2.  **게스트 풀 확장 및 육성:**\n",
            "    *   **개선 방안:** 기존 인기 게스트들의 꾸준한 출연을 유지하되, 이들과 유사한 통찰력과 대화 능력을 갖춘 새로운 전문가나 아티스트를 꾸준히 발굴하고 소개합니다. '숨겨진 보석' 같은 인물을 발굴하여 시청자들에게 새로운 발견의 재미를 제공하고, 특정 게스트 의존도를 분산시키는 노력이 필요합니다.\n",
            "3.  **롱폼 콘텐츠의 '티징' 및 '하이라이트' 전략 도입:**\n",
            "    *   **개선 방안:** 롱폼 영상에서 핵심적인 '킬링 포인트'나 '인사이트'가 담긴 짧은 클립을 제작하여 쇼츠, 인스타그램 릴스 등 숏폼 플랫폼에 적극적으로 활용합니다. 이는 롱폼 시청에 부담을 느끼는 잠재 시청자들의 관심을 유도하여 본편으로 유입시키는 효과적인 방법이 될 수 있습니다. 1시간짜리 영상을 보고 \"19분? 쇼츠네...\"라는 댓글처럼 긴 영상을 재밌게 본 시청자들도 숏폼의 필요성을 간접적으로 어필하는 것으로 해석할 수 있습니다.\n",
            "4.  **시청자 피드백을 활용한 콘텐츠 기획 시스템화:**\n",
            "    *   **개선 방안:** 댓글에서 게스트 요청, 주제 제안, 플레이리스트 요청 등 시청자들의 구체적인 니즈가 많이 나타나고 있습니다. 이를 일회성에 그치지 않고 정기적으로 모니터링하고, 실제 콘텐츠 기획 회의에 반영하는 시스템을 구축합니다. 예를 들어, 매 분기 시청자 투표를 통해 다음 시즌 '토킹 헤즈' 주제나 '머니 코드' 아티스트를 선정하는 방식을 고려해볼 수 있습니다. 이는 시청자들의 주인의식과 참여도를 더욱 높일 것입니다.\n",
            "\n",
            "---\n",
            "\n",
            "'@Moneygraphy' 채널은 깊이 있는 콘텐츠와 독창적인 접근 방식으로 유튜브 시장에서 보기 드문 성공을 거두고 있습니다. 위에 제시된 전략 제안과 주의사항을 바탕으로 채널의 강점을 더욱 강화하고, 잠재적 위험 요소를 관리한다면 지속적인 성장과 더 넓은 시청자층 확보가 가능할 것으로 기대합니다.\n",
            "============================================================\n",
            "\n",
            "AI 분석 결과 저장: ai_analysis_20250916_204615.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 최종 결과 요약\n",
        "# =================================================================\n",
        "\n",
        "\n",
        "# 수집된 데이터 요약\n",
        "total_views = videos_df['view_count'].sum() if not videos_df.empty else 0\n",
        "avg_views = videos_df['view_count'].mean() if not videos_df.empty else 0\n",
        "\n",
        "print(f\"\\n수집 결과 요약:\")\n",
        "print(f\"  분석 채널: {CHANNEL_NAME}\")\n",
        "print(f\"  수집 영상: {len(videos_df)}개\")\n",
        "print(f\"  수집 댓글: {len(comments_df)}개\")\n",
        "print(f\"  총 조회수: {total_views:,}회\")\n",
        "print(f\"  평균 조회수: {avg_views:,.0f}회\")\n",
        "\n",
        "# 저장된 파일 목록\n",
        "print(f\"\\n저장된 파일:\")\n",
        "files = os.listdir(SAVE_PATH)\n",
        "today_files = [f for f in files if timestamp in f]\n",
        "for file in sorted(today_files):\n",
        "    print(f\"  - {file}\")\n",
        "\n",
        "print(f\"\\n모든 결과는 다음 위치에 저장되었습니다:\")\n",
        "print(f\"{SAVE_PATH}\")\n",
        "\n",
        "print(f\"\\n1일차 실습이 완료되었습니다!\")\n",
        "print(\"수고하셨습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sEklriwYqN8",
        "outputId": "a3b0bbb4-64af-4dbb-f919-d991e3d68e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "수집 결과 요약:\n",
            "  분석 채널: @Moneygraphy\n",
            "  수집 영상: 10개\n",
            "  수집 댓글: 300개\n",
            "  총 조회수: 1,896,656회\n",
            "  평균 조회수: 189,666회\n",
            "\n",
            "저장된 파일:\n",
            "  - ai_analysis_20250916_204615.txt\n",
            "  - comments_20250916_204615.csv\n",
            "  - videos_20250916_204615.csv\n",
            "\n",
            "모든 결과는 다음 위치에 저장되었습니다:\n",
            "/content/drive/MyDrive/youtube_analysis/\n",
            "\n",
            "1일차 실습이 완료되었습니다!\n",
            "수고하셨습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "---\n",
        "\n",
        "# 1일차 실습에서 배운 내용:\n",
        "\n",
        "1. yt-dlp로 YouTube 영상 정보 수집하기\n",
        "   - 채널의 최신 영상 목록 가져오기\n",
        "   - 각 영상의 상세 정보 (조회수, 좋아요, 댓글 수 등) 수집\n",
        "   - 날짜와 조회수 조건으로 필터링하기\n",
        "\n",
        "2. YouTube Data API로 댓글 수집하기\n",
        "   - 인기 댓글 위주로 효율적 수집\n",
        "   - API 사용량 관리하기\n",
        "\n",
        "3. 데이터 저장하고 관리하기\n",
        "   - CSV 파일로 저장 (엑셀에서 열어볼 수 있음)\n",
        "   - 파일명에 시간 정보 포함해서 중복 방지\n",
        "\n",
        "4. AI를 활용한 데이터 분석\n",
        "   - 수집한 데이터를 AI에게 분석 요청\n",
        "   - 실용적인 콘텐츠 전략 도출"
      ],
      "metadata": {
        "id": "qtQEv8G-vJWv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QgfjebNWXGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}